#!/usr/bin/env python3
"""
=== AdaptiveRAG å®éªŒè¿è¡Œè„šæœ¬ ===

ä¸€é”®è¿è¡Œå®Œæ•´çš„åŸºå‡†æµ‹è¯•å®éªŒï¼Œç”Ÿæˆè®ºæ–‡æ‰€éœ€çš„å®éªŒç»“æœ
"""

import argparse
import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from adaptive_rag.evaluation.dataset_downloader import DatasetDownloader
from adaptive_rag.evaluation.benchmark_runner import BenchmarkRunner, BenchmarkConfig

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def setup_datasets(use_sample_data: bool = True):
    """è®¾ç½®æ•°æ®é›†"""
    logger.info("ğŸ“Š è®¾ç½®è¯„ä¼°æ•°æ®é›†")
    
    downloader = DatasetDownloader()
    
    if use_sample_data:
        # ä½¿ç”¨æ ·æœ¬æ•°æ®è¿›è¡Œå¿«é€Ÿæµ‹è¯•
        logger.info("ä½¿ç”¨æ ·æœ¬æ•°æ®é›†è¿›è¡Œæµ‹è¯•")
        downloader.create_sample_datasets()
    else:
        # ä¸‹è½½çœŸå®æ•°æ®é›†
        logger.info("ä¸‹è½½çœŸå®æ•°æ®é›† (éœ€è¦ç½‘ç»œè¿æ¥)")
        downloader.download_all_datasets()
    
    logger.info("âœ… æ•°æ®é›†è®¾ç½®å®Œæˆ")


def run_quick_experiment():
    """è¿è¡Œå¿«é€Ÿå®éªŒ (ç”¨äºå¼€å‘å’Œè°ƒè¯•)"""
    logger.info("ğŸš€ è¿è¡Œå¿«é€Ÿå®éªŒ")
    
    config = BenchmarkConfig(
        datasets=["natural_questions", "hotpot_qa"],
        methods=["adaptive_rag", "naive_rag"],
        output_dir="./experiments/quick_test",
        max_samples=20,  # åªä½¿ç”¨20ä¸ªæ ·æœ¬
        save_predictions=True,
        compute_bert_score=False  # è·³è¿‡ BERTScore ä»¥èŠ‚çœæ—¶é—´
    )
    
    runner = BenchmarkRunner(config)
    runner.run_benchmark()
    
    logger.info("âœ… å¿«é€Ÿå®éªŒå®Œæˆ")


def run_full_experiment():
    """è¿è¡Œå®Œæ•´å®éªŒ (ç”¨äºè®ºæ–‡ç»“æœ)"""
    logger.info("ğŸš€ è¿è¡Œå®Œæ•´å®éªŒ")
    
    config = BenchmarkConfig(
        datasets=[
            # å•è·³é—®ç­”
            "natural_questions",
            "trivia_qa", 
            "ms_marco",
            
            # å¤šè·³æ¨ç†
            "hotpot_qa",
            # "2wiki_multihop",  # å¦‚æœæœ‰çš„è¯
            # "musique",         # å¦‚æœæœ‰çš„è¯
        ],
        methods=[
            "adaptive_rag",      # æˆ‘ä»¬çš„æ–¹æ³•
            "naive_rag",         # æœ´ç´ åŸºçº¿
            "self_rag",          # é«˜çº§åŸºçº¿
            # "raptor",          # å¦‚æœå®ç°çš„è¯
            # "hyde",            # å¦‚æœå®ç°çš„è¯
        ],
        output_dir="./experiments/full_evaluation",
        max_samples=None,  # ä½¿ç”¨å…¨éƒ¨æ•°æ®
        save_predictions=True,
        compute_bert_score=True
    )
    
    runner = BenchmarkRunner(config)
    runner.run_benchmark()
    
    logger.info("âœ… å®Œæ•´å®éªŒå®Œæˆ")


def run_ablation_study():
    """è¿è¡Œæ¶ˆèç ”ç©¶ - è¯¦ç»†åˆ†æå„ç»„ä»¶è´¡çŒ®"""
    logger.info("ğŸ”¬ è¿è¡Œè¯¦ç»†æ¶ˆèç ”ç©¶")

    # å®Œæ•´çš„æ¶ˆèç ”ç©¶è®¾è®¡
    ablation_experiments = {
        # 1. å®Œæ•´æ–¹æ³•ä½œä¸ºåŸºå‡†
        "full_method": {
            "methods": ["adaptive_rag"],
            "description": "å®Œæ•´çš„ AdaptiveRAG æ–¹æ³•"
        },

        # 2. ä»»åŠ¡åˆ†è§£æ¶ˆè
        "task_decomposition": {
            "methods": [
                "adaptive_rag",
                "adaptive_rag_no_decomposition"
            ],
            "description": "ä»»åŠ¡åˆ†è§£ç»„ä»¶çš„å½±å“"
        },

        # 3. ç­–ç•¥è§„åˆ’æ¶ˆè
        "strategy_planning": {
            "methods": [
                "adaptive_rag",
                "adaptive_rag_no_planning"
            ],
            "description": "ç­–ç•¥è§„åˆ’ç»„ä»¶çš„å½±å“"
        },

        # 4. å¤šæ£€ç´¢å™¨æ¶ˆè
        "multi_retriever": {
            "methods": [
                "adaptive_rag",
                "adaptive_rag_single_retriever"
            ],
            "description": "å¤šæ£€ç´¢å™¨èåˆçš„å½±å“"
        },

        # 5. é‡æ’åºæ¶ˆè
        "reranking": {
            "methods": [
                "adaptive_rag",
                "adaptive_rag_no_reranking"
            ],
            "description": "é‡æ’åºç»„ä»¶çš„å½±å“"
        },

        # 6. å®Œæ•´æ¶ˆèå¯¹æ¯”
        "complete_ablation": {
            "methods": [
                "adaptive_rag",                    # å®Œæ•´æ–¹æ³•
                "adaptive_rag_no_decomposition",   # æ— ä»»åŠ¡åˆ†è§£
                "adaptive_rag_no_planning",        # æ— ç­–ç•¥è§„åˆ’
                "adaptive_rag_single_retriever",   # å•ä¸€æ£€ç´¢å™¨
                "adaptive_rag_no_reranking",       # æ— é‡æ’åº
                "naive_rag",                       # æœ´ç´ åŸºçº¿
            ],
            "description": "å®Œæ•´çš„æ¶ˆèå¯¹æ¯”ç ”ç©¶"
        }
    }

    # è¿è¡Œå„ä¸ªæ¶ˆèå®éªŒ
    for exp_name, exp_config in ablation_experiments.items():
        logger.info(f"\nğŸ§ª è¿è¡Œæ¶ˆèå®éªŒ: {exp_name}")
        logger.info(f"ğŸ“ æè¿°: {exp_config['description']}")

        config = BenchmarkConfig(
            datasets=["natural_questions", "hotpot_qa"],
            methods=exp_config["methods"],
            output_dir=f"./experiments/ablation_study/{exp_name}",
            max_samples=100,  # é€‚ä¸­çš„æ ·æœ¬æ•°é‡
            save_predictions=True,
            compute_bert_score=True
        )

        runner = BenchmarkRunner(config)
        runner.run_benchmark()

        logger.info(f"âœ… æ¶ˆèå®éªŒ {exp_name} å®Œæˆ")

    # ç”Ÿæˆæ¶ˆèåˆ†ææŠ¥å‘Š
    _generate_ablation_report()

    logger.info("âœ… è¯¦ç»†æ¶ˆèç ”ç©¶å®Œæˆ")


def _generate_ablation_report():
    """ç”Ÿæˆæ¶ˆèåˆ†ææŠ¥å‘Š"""
    logger.info("ğŸ“Š ç”Ÿæˆæ¶ˆèåˆ†ææŠ¥å‘Š")

    # è¿™é‡Œå¯ä»¥æ·»åŠ ç»“æœåˆ†æå’Œå¯è§†åŒ–ä»£ç 
    # ä¾‹å¦‚ï¼šå¯¹æ¯”ä¸åŒç»„ä»¶çš„æ€§èƒ½è´¡çŒ®

    report_content = """
# AdaptiveRAG æ¶ˆèç ”ç©¶æŠ¥å‘Š

## å®éªŒè®¾è®¡

æœ¬æ¶ˆèç ”ç©¶æ—¨åœ¨åˆ†æ AdaptiveRAG å„ç»„ä»¶çš„è´¡çŒ®åº¦ï¼š

1. **ä»»åŠ¡åˆ†è§£ (Task Decomposition)**: LLM é©±åŠ¨çš„æŸ¥è¯¢åˆ†æå’Œå­ä»»åŠ¡åˆ†è§£
2. **ç­–ç•¥è§„åˆ’ (Strategy Planning)**: è‡ªé€‚åº”æ£€ç´¢ç­–ç•¥é€‰æ‹©
3. **å¤šæ£€ç´¢å™¨èåˆ (Multi-Retriever)**: å…³é”®è¯ã€å¯†é›†ã€Web æ£€ç´¢çš„æ™ºèƒ½èåˆ
4. **é‡æ’åº (Reranking)**: æ£€ç´¢ç»“æœçš„é‡æ–°æ’åºå’Œç­›é€‰

## å®éªŒç»“æœ

è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹å„ä¸ªå®éªŒç›®å½•ä¸‹çš„ç»“æœæ–‡ä»¶ã€‚

## åˆ†æç»“è®º

[å¾…è¡¥å……ï¼šåŸºäºå®éªŒç»“æœçš„åˆ†æ]

"""

    report_path = "./experiments/ablation_study/ablation_report.md"
    os.makedirs(os.path.dirname(report_path), exist_ok=True)

    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)

    logger.info(f"ğŸ“„ æ¶ˆèæŠ¥å‘Šå·²ä¿å­˜: {report_path}")


def run_efficiency_analysis():
    """è¿è¡Œæ•ˆç‡åˆ†æ"""
    logger.info("âš¡ è¿è¡Œæ•ˆç‡åˆ†æ")
    
    config = BenchmarkConfig(
        datasets=["natural_questions"],  # ä½¿ç”¨å•ä¸€æ•°æ®é›†
        methods=["adaptive_rag", "naive_rag", "self_rag"],
        output_dir="./experiments/efficiency_analysis",
        max_samples=100,
        save_predictions=False,  # ä¸ä¿å­˜é¢„æµ‹ä»¥èŠ‚çœç©ºé—´
        compute_bert_score=False  # ä¸“æ³¨äºæ—¶é—´åˆ†æ
    )
    
    runner = BenchmarkRunner(config)
    runner.run_benchmark()
    
    logger.info("âœ… æ•ˆç‡åˆ†æå®Œæˆ")


def generate_paper_results():
    """ç”Ÿæˆè®ºæ–‡æ‰€éœ€çš„æ‰€æœ‰ç»“æœ"""
    logger.info("ğŸ“ ç”Ÿæˆè®ºæ–‡ç»“æœ")
    
    # 1. è®¾ç½®æ•°æ®é›†
    setup_datasets(use_sample_data=False)  # ä½¿ç”¨çœŸå®æ•°æ®
    
    # 2. è¿è¡Œä¸»è¦å®éªŒ
    run_full_experiment()
    
    # 3. è¿è¡Œæ¶ˆèç ”ç©¶
    run_ablation_study()
    
    # 4. è¿è¡Œæ•ˆç‡åˆ†æ
    run_efficiency_analysis()
    
    logger.info("ğŸ‰ è®ºæ–‡ç»“æœç”Ÿæˆå®Œæˆï¼")
    logger.info("ğŸ“ ç»“æœä¿å­˜åœ¨ ./experiments/ ç›®å½•ä¸‹")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="AdaptiveRAG å®éªŒè¿è¡Œå™¨")
    parser.add_argument(
        "experiment_type",
        choices=["quick", "full", "ablation", "efficiency", "paper"],
        help="å®éªŒç±»å‹"
    )
    parser.add_argument(
        "--sample-data",
        action="store_true",
        help="ä½¿ç”¨æ ·æœ¬æ•°æ®è€Œä¸æ˜¯çœŸå®æ•°æ®é›†"
    )
    
    args = parser.parse_args()
    
    logger.info(f"ğŸ§ª å¼€å§‹è¿è¡Œ {args.experiment_type} å®éªŒ")
    
    try:
        if args.experiment_type == "quick":
            setup_datasets(use_sample_data=True)
            run_quick_experiment()
            
        elif args.experiment_type == "full":
            setup_datasets(use_sample_data=args.sample_data)
            run_full_experiment()
            
        elif args.experiment_type == "ablation":
            setup_datasets(use_sample_data=args.sample_data)
            run_ablation_study()
            
        elif args.experiment_type == "efficiency":
            setup_datasets(use_sample_data=args.sample_data)
            run_efficiency_analysis()
            
        elif args.experiment_type == "paper":
            generate_paper_results()
        
        logger.info("ğŸ‰ å®éªŒè¿è¡ŒæˆåŠŸå®Œæˆï¼")
        
        # æ˜¾ç¤ºç»“æœä½ç½®
        experiments_dir = Path("./experiments")
        if experiments_dir.exists():
            logger.info(f"ğŸ“ å®éªŒç»“æœä¿å­˜åœ¨: {experiments_dir.absolute()}")
            
            # åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶
            for result_dir in experiments_dir.iterdir():
                if result_dir.is_dir():
                    logger.info(f"   ğŸ“‚ {result_dir.name}/")
                    for file in result_dir.iterdir():
                        if file.is_file():
                            logger.info(f"      ğŸ“„ {file.name}")
        
    except Exception as e:
        logger.error(f"âŒ å®éªŒè¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
