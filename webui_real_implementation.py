#!/usr/bin/env python3
"""
=== AdaptiveRAG WebUI with Real Implementation ===

ä½¿ç”¨çœŸå®æ£€ç´¢å™¨ã€ç”Ÿæˆå™¨å’Œé‡æ’åºå™¨çš„ AdaptiveRAG WebUI
"""

import gradio as gr
import json
import yaml
import time
import logging
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class RealAdaptiveRAGEngine:
    """ä½¿ç”¨çœŸå®ç»„ä»¶çš„ AdaptiveRAG å¼•æ“"""

    def __init__(self, config_path: str = "real_config.yaml"):
        """åˆå§‹åŒ–å¼•æ“"""
        self.config_path = config_path
        self.config = self.load_config()
        self.last_results = None

        # åˆå§‹åŒ–çœŸå®ç»„ä»¶
        self.initialize_real_components()

        logger.info("ğŸš€ çœŸå® AdaptiveRAG å¼•æ“åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   é…ç½®æ–‡ä»¶: {self.config_path}")

    def load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            logger.info(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {self.config_path}")
            return config
        except Exception as e:
            logger.error(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            return self.get_default_config()

    def get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "device": "cuda",
            "retriever_configs": {},
            "generator_configs": {},
            "ranker_configs": {}
        }

    def initialize_real_components(self):
        """åˆå§‹åŒ–çœŸå®ç»„ä»¶"""
        try:
            # å°è¯•åˆå§‹åŒ–çœŸå®çš„ FlexRAG ç»„ä»¶
            from adaptive_rag.core.flexrag_integrated_assistant import FlexRAGIntegratedAssistant

            # ä½¿ç”¨çœŸå®é…ç½®åˆ›å»ºåŠ©æ‰‹
            self.assistant = FlexRAGIntegratedAssistant()
            self.use_real_components = True
            logger.info("âœ… çœŸå® FlexRAG ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")

        except Exception as e:
            logger.warning(f"âš ï¸ çœŸå®ç»„ä»¶åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå®ç°: {e}")
            self.assistant = None
            self.use_real_components = False

    def get_config_summary(self) -> str:
        """è·å–é…ç½®æ‘˜è¦"""
        summary = []
        summary.append("ğŸ“‹ **å½“å‰é…ç½®æ‘˜è¦**\n")

        # åŸºç¡€è®¾ç½®
        summary.append(f"ğŸ–¥ï¸ **è®¾å¤‡**: {self.config.get('device', 'N/A')}")
        summary.append(f"ğŸ”¢ **æ‰¹æ¬¡å¤§å°**: {self.config.get('batch_size', 'N/A')}")
        summary.append(f"ğŸ¯ **æ•°æ®é›†**: {self.config.get('dataset_name', 'N/A')}")
        summary.append(f"ğŸ”§ **ä½¿ç”¨çœŸå®ç»„ä»¶**: {'âœ… æ˜¯' if self.use_real_components else 'âŒ å¦'}")

        # æ£€ç´¢å™¨é…ç½®
        retrievers = self.config.get('retriever_configs', {})
        summary.append(f"\nğŸ” **æ£€ç´¢å™¨é…ç½®** ({len(retrievers)} ä¸ª):")
        for name, config in retrievers.items():
            retriever_type = config.get('retriever_type', 'unknown')
            status = "âœ… çœŸå®" if retriever_type != "mock" else "ğŸ”„ æ¨¡æ‹Ÿ"
            model_name = config.get('model_name', 'N/A')
            model_path = config.get('model_path', 'N/A')
            summary.append(f"   â€¢ **{name}**: {retriever_type} {status}")
            summary.append(f"     - æ¨¡å‹: {model_name}")
            summary.append(f"     - è·¯å¾„: {model_path}")

        # ç”Ÿæˆå™¨é…ç½®
        generators = self.config.get('generator_configs', {})
        summary.append(f"\nğŸ¤– **ç”Ÿæˆå™¨é…ç½®** ({len(generators)} ä¸ª):")
        for name, config in generators.items():
            generator_type = config.get('generator_type', 'unknown')
            status = "âœ… çœŸå®" if generator_type != "mock" else "ğŸ”„ æ¨¡æ‹Ÿ"
            model_name = config.get('model_name', 'N/A')
            model_path = config.get('model_path', 'N/A')
            summary.append(f"   â€¢ **{name}**: {generator_type} {status}")
            summary.append(f"     - æ¨¡å‹: {model_name}")
            summary.append(f"     - è·¯å¾„: {model_path}")

        # é‡æ’åºå™¨é…ç½®
        rankers = self.config.get('ranker_configs', {})
        summary.append(f"\nğŸ“Š **é‡æ’åºå™¨é…ç½®** ({len(rankers)} ä¸ª):")
        for name, config in rankers.items():
            ranker_type = config.get('ranker_type', 'unknown')
            status = "âœ… çœŸå®" if ranker_type != "mock" else "ğŸ”„ æ¨¡æ‹Ÿ"
            model_name = config.get('model_name', 'N/A')
            model_path = config.get('model_path', 'N/A')
            summary.append(f"   â€¢ **{name}**: {ranker_type} {status}")
            summary.append(f"     - æ¨¡å‹: {model_name}")
            summary.append(f"     - è·¯å¾„: {model_path}")

        # è·¯å¾„ä¿¡æ¯
        summary.append(f"\nğŸ“ **è·¯å¾„é…ç½®**:")
        summary.append(f"   â€¢ è¯­æ–™åº“: {self.config.get('corpus_path', 'N/A')}")
        summary.append(f"   â€¢ ç´¢å¼•æ–‡ä»¶: {self.config.get('index_path', 'N/A')}")
        summary.append(f"   â€¢ æ¨¡å‹ç›®å½•: {self.config.get('models_dir', 'N/A')}")

        return "\n".join(summary)

    def process_query(self, query: str, show_details: bool = True) -> Dict[str, Any]:
        """å¤„ç†æŸ¥è¯¢ï¼ˆä½¿ç”¨çœŸå®ç»„ä»¶æˆ–æ¨¡æ‹Ÿå®ç°ï¼‰"""
        start_time = time.time()

        logger.info(f"ğŸ” å¤„ç†æŸ¥è¯¢: {query}")

        if self.use_real_components and self.assistant:
            # ä½¿ç”¨çœŸå®çš„ FlexRAG ç»„ä»¶
            try:
                result = self.process_with_real_components(query, show_details)
                logger.info("âœ… ä½¿ç”¨çœŸå®ç»„ä»¶å¤„ç†å®Œæˆ")
                return result
            except Exception as e:
                logger.error(f"âŒ çœŸå®ç»„ä»¶å¤„ç†å¤±è´¥: {e}")
                logger.info("ğŸ”„ å›é€€åˆ°æ¨¡æ‹Ÿå®ç°")

        # å›é€€åˆ°æ¨¡æ‹Ÿå®ç°
        return self.process_with_simulation(query, show_details)

    def process_with_real_components(self, query: str, show_details: bool = True) -> Dict[str, Any]:
        """ä½¿ç”¨çœŸå®ç»„ä»¶å¤„ç†æŸ¥è¯¢"""
        start_time = time.time()

        # ä½¿ç”¨ FlexRAG é›†æˆåŠ©æ‰‹å¤„ç†æŸ¥è¯¢
        result = self.assistant.process_query(query, show_details)

        total_time = time.time() - start_time

        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        processed_result = {
            "query": query,
            "answer": result.get("answer", ""),
            "retrieved_docs": result.get("retrieved_docs", []),
            "processing_details": result.get("processing_details", {}),
            "total_time": total_time,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "method": "real_components",
            "stages": {
                "query_analysis": {
                    "processing_time": result.get("processing_details", {}).get("query_analysis_time", 0),
                    "status": "âœ… å®Œæˆï¼ˆçœŸå®ï¼‰"
                },
                "strategy_planning": {
                    "processing_time": result.get("processing_details", {}).get("strategy_planning_time", 0),
                    "status": "âœ… å®Œæˆï¼ˆçœŸå®ï¼‰"
                },
                "retrieval": {
                    "processing_time": result.get("processing_details", {}).get("retrieval_time", 0),
                    "status": "âœ… å®Œæˆï¼ˆçœŸå®ï¼‰",
                    "retriever_results": self.format_real_retrieval_results(result.get("retrieved_docs", []))
                },
                "reranking": {
                    "processing_time": result.get("processing_details", {}).get("reranking_time", 0),
                    "status": "âœ… å®Œæˆï¼ˆçœŸå®ï¼‰"
                },
                "generation": {
                    "processing_time": result.get("processing_details", {}).get("generation_time", 0),
                    "status": "âœ… å®Œæˆï¼ˆçœŸå®ï¼‰",
                    "generated_answer": result.get("answer", "")
                }
            }
        }

        self.last_results = processed_result
        return processed_result

    def format_real_retrieval_results(self, docs: List[Dict]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–çœŸå®æ£€ç´¢ç»“æœ"""
        # æŒ‰æ£€ç´¢å™¨ç±»å‹åˆ†ç»„
        retriever_results = {}

        for doc in docs:
            source = doc.get("source", "unknown_retriever")
            if source not in retriever_results:
                retriever_results[source] = {
                    "type": "real",
                    "documents": [],
                    "total_found": 0,
                    "processing_time": 0.1
                }

            retriever_results[source]["documents"].append({
                "id": doc.get("id", "unknown"),
                "title": doc.get("title", "Unknown Document"),
                "content": doc.get("content", "")[:200] + "...",
                "score": doc.get("score", 0.0),
                "source": source
            })
            retriever_results[source]["total_found"] += 1

        return retriever_results

    def process_with_simulation(self, query: str, show_details: bool = True) -> Dict[str, Any]:
        """ä½¿ç”¨æ¨¡æ‹Ÿå®ç°å¤„ç†æŸ¥è¯¢"""
        start_time = time.time()

        # æ¨¡æ‹Ÿå„ä¸ªé˜¶æ®µï¼ˆä¿æŒåŸæœ‰çš„æ¨¡æ‹Ÿé€»è¾‘ï¼‰
        stages = {
            "query_analysis": self.simulate_query_analysis(query),
            "strategy_planning": self.simulate_strategy_planning(query),
            "retrieval": self.simulate_retrieval(query),
            "reranking": self.simulate_reranking(query),
            "generation": self.simulate_generation(query)
        }

        total_time = time.time() - start_time

        result = {
            "query": query,
            "stages": stages,
            "total_time": total_time,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "answer": stages["generation"]["generated_answer"],
            "retrieved_docs": stages["retrieval"]["retriever_results"],
            "method": "simulation",
            "processing_details": {
                "query_analysis_time": stages["query_analysis"]["processing_time"],
                "strategy_planning_time": stages["strategy_planning"]["processing_time"],
                "retrieval_time": stages["retrieval"]["processing_time"],
                "reranking_time": stages["reranking"]["processing_time"],
                "generation_time": stages["generation"]["processing_time"]
            }
        }

        self.last_results = result
        return result

    def simulate_query_analysis(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹ŸæŸ¥è¯¢åˆ†æé˜¶æ®µ"""
        time.sleep(0.1)

        words = query.lower().split()
        complexity_score = min(len(words) / 10.0, 1.0)

        question_words = ['what', 'who', 'where', 'when', 'why', 'how']
        has_question_word = any(word in words for word in question_words)

        multi_hop_indicators = ['and', 'also', 'furthermore', 'additionally', 'where', 'author', 'creator']
        is_multi_hop = any(indicator in words for indicator in multi_hop_indicators)

        return {
            "complexity_score": complexity_score,
            "word_count": len(words),
            "has_question_word": has_question_word,
            "is_multi_hop": is_multi_hop,
            "query_type": "multi_hop" if is_multi_hop else "single_hop",
            "processing_time": 0.1,
            "status": "âœ… å®Œæˆï¼ˆæ¨¡æ‹Ÿï¼‰"
        }

    def simulate_strategy_planning(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿç­–ç•¥è§„åˆ’é˜¶æ®µ"""
        time.sleep(0.1)

        analysis = self.simulate_query_analysis(query)

        # æ ¹æ®çœŸå®é…ç½®ä¸­çš„ç­–ç•¥æƒé‡
        strategy_config = self.config.get('retrieval_strategy', {})
        task_weights = strategy_config.get('task_specific_weights', {})

        if analysis["is_multi_hop"]:
            weights = task_weights.get('multi_hop', {"keyword": 0.3, "dense": 0.5, "web": 0.2})
            strategy = "multi_hop_strategy"
        else:
            weights = task_weights.get('factual', {"keyword": 0.6, "dense": 0.3, "web": 0.1})
            strategy = "single_hop_strategy"

        return {
            "selected_strategy": strategy,
            "retriever_weights": weights,
            "confidence": 0.85,
            "reasoning": f"åŸºäºæŸ¥è¯¢å¤æ‚åº¦ {analysis['complexity_score']:.2f} å’Œé…ç½®æƒé‡é€‰æ‹©ç­–ç•¥",
            "processing_time": 0.1,
            "status": "âœ… å®Œæˆï¼ˆæ¨¡æ‹Ÿï¼‰"
        }

    def simulate_retrieval(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæ£€ç´¢é˜¶æ®µ"""
        time.sleep(0.2)

        retrievers = self.config.get('retriever_configs', {})
        results = {}

        for retriever_name, config in retrievers.items():
            retriever_type = config.get('retriever_type', 'mock')
            top_k = config.get('top_k', 5)
            model_name = config.get('model_name', 'unknown')

            docs = []
            for i in range(top_k):
                docs.append({
                    "id": f"{retriever_name}_doc_{i}",
                    "title": f"Document {i} from {retriever_name}",
                    "content": f"Content retrieved by {model_name} for query: {query[:50]}... (æ¨¡æ‹Ÿæ•°æ®)",
                    "score": 0.9 - i * 0.1,
                    "source": retriever_name,
                    "model": model_name,
                    "note": "âš ï¸ è¿™æ˜¯æ¨¡æ‹Ÿæ•°æ®"
                })

            results[retriever_name] = {
                "type": retriever_type,
                "model": model_name,
                "documents": docs,
                "total_found": top_k,
                "processing_time": 0.05,
                "status": "âœ… å®Œæˆï¼ˆæ¨¡æ‹Ÿï¼‰"
            }

        return {
            "retriever_results": results,
            "total_documents": sum(len(r["documents"]) for r in results.values()),
            "processing_time": 0.2,
            "status": "âœ… å®Œæˆï¼ˆæ¨¡æ‹Ÿï¼‰"
        }

    def simulate_reranking(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿé‡æ’åºé˜¶æ®µ"""
        time.sleep(0.1)

        rankers = self.config.get('ranker_configs', {})

        reranked_docs = []
        for i in range(5):
            reranked_docs.append({
                "id": f"reranked_doc_{i}",
                "title": f"Reranked Document {i}",
                "content": f"Reranked content for: {query[:50]}... (æ¨¡æ‹Ÿæ•°æ®)",
                "original_score": 0.8 - i * 0.1,
                "rerank_score": 0.95 - i * 0.05,
                "rank_change": i % 3 - 1,
                "note": "âš ï¸ è¿™æ˜¯æ¨¡æ‹Ÿæ•°æ®"
            })

        ranker_name = list(rankers.keys())[0] if rankers else "default"
        ranker_model = rankers.get(ranker_name, {}).get('model_name', 'default') if rankers else "default"

        return {
            "ranker_used": ranker_name,
            "ranker_model": ranker_model,
            "reranked_documents": reranked_docs,
            "score_improvement": 0.15,
            "processing_time": 0.1,
            "status": "âœ… å®Œæˆï¼ˆæ¨¡æ‹Ÿï¼‰"
        }

    def simulate_generation(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿç”Ÿæˆé˜¶æ®µ"""
        time.sleep(0.3)

        generators = self.config.get('generator_configs', {})
        main_generator = list(generators.keys())[0] if generators else "default"
        generator_model = generators.get(main_generator, {}).get('model_name', 'default') if generators else "default"

        answer = f"Based on the retrieved information using {generator_model}, here's the answer to '{query}': This is a response generated with real configuration settings from the AdaptiveRAG system. âš ï¸ æ³¨æ„ï¼šè¿™æ˜¯æ¨¡æ‹Ÿç”Ÿæˆçš„ç­”æ¡ˆã€‚"

        return {
            "generator_used": main_generator,
            "generator_model": generator_model,
            "generated_answer": answer,
            "confidence": 0.88,
            "token_count": len(answer.split()),
            "processing_time": 0.3,
            "status": "âœ… å®Œæˆï¼ˆæ¨¡æ‹Ÿï¼‰"
        }

def create_webui(config_path: str = "real_config.yaml") -> gr.Blocks:
    """åˆ›å»ºä½¿ç”¨çœŸå®ç»„ä»¶çš„ WebUI"""

    # åˆå§‹åŒ–å¼•æ“
    engine = RealAdaptiveRAGEngine(config_path)

    # è‡ªå®šä¹‰ CSSï¼ˆä¿æŒåŸæœ‰é£æ ¼ï¼‰
    custom_css = """
    /* å…¨å®½å¸ƒå±€ */
    .gradio-container, .main, .container {
        max-width: none !important;
        margin: 0 !important;
        padding: 0 !important;
    }

    .tab-nav {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        border-radius: 8px 8px 0 0;
    }

    .primary-button {
        background: linear-gradient(45deg, #667eea, #764ba2);
        border: none;
        color: white;
        border-radius: 6px;
        transition: all 0.3s ease;
    }

    .primary-button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
    }

    body {
        margin: 0 !important;
        max-width: none !important;
        padding: 0 !important;
    }

    .title-container {
        text-align: center;
        margin: 0;
        padding: 30px 20px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 12px;
        box-shadow: 0 4px 20px rgba(102, 126, 234, 0.3);
        width: 100%;
        box-sizing: border-box;
    }

    .tab-item {
        border-radius: 8px;
        margin: 2px;
        flex-grow: 1;
    }

    .gr-textbox, .gr-slider {
        border-radius: 6px;
        border: 1px solid #e1e5e9;
    }

    .gr-button {
        border-radius: 6px;
        transition: all 0.3s ease;
    }

    @media (max-width: 768px) {
        .gradio-container, .main, .container {
            max-width: 100% !important;
            padding: 10px !important;
        }

        .title-container {
            margin: 0;
            padding: 15px;
        }
    }
    """

    with gr.Blocks(
        title="ğŸ§  æ™ºèƒ½è‡ªé€‚åº” RAG ç³»ç»Ÿ - çœŸå®å®ç°",
        theme=gr.themes.Soft(
            primary_hue="blue",
            secondary_hue="purple",
            neutral_hue="slate",
            spacing_size="md",
            radius_size="md"
        ),
        css=custom_css
    ) as demo:

        # æ ‡é¢˜å’Œä»‹ç»
        gr.HTML("""
        <div class="title-container">
            <h1 style="margin: 0 0 10px 0; font-size: 2.5em; font-weight: 700;">
                ğŸ§  æ™ºèƒ½è‡ªé€‚åº” RAG ç³»ç»Ÿ
            </h1>
            <h3 style="margin: 0 0 15px 0; font-size: 1.3em; font-weight: 400; opacity: 0.9;">
                åŸºäºçœŸå®ç»„ä»¶çš„å¢å¼ºæ£€ç´¢ç”Ÿæˆç³»ç»Ÿ
            </h3>
            <p style="margin: 0; font-size: 1em; opacity: 0.8; line-height: 1.6;">
                ä½¿ç”¨çœŸå®çš„æ£€ç´¢å™¨ã€ç”Ÿæˆå™¨å’Œé‡æ’åºå™¨ï¼Œå±•ç¤ºå®Œæ•´çš„ AdaptiveRAG æµç¨‹
            </p>
        </div>
        """)

        # åˆ›å»ºæ ‡ç­¾é¡µ
        with gr.Tabs():
            # é…ç½®ä¿¡æ¯æ ‡ç­¾é¡µ
            with gr.Tab("âš™ï¸ é…ç½®ä¿¡æ¯"):
                gr.HTML("<h2>ğŸ“‹ ç³»ç»Ÿé…ç½®ä¿¡æ¯</h2>")

                config_display = gr.Markdown(
                    value=engine.get_config_summary(),
                    label="é…ç½®æ‘˜è¦"
                )

                with gr.Row():
                    refresh_config_btn = gr.Button("ğŸ”„ åˆ·æ–°é…ç½®", variant="secondary")
                    reload_config_btn = gr.Button("ğŸ“ é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶", variant="primary")

                config_status = gr.Textbox(
                    label="çŠ¶æ€",
                    value="é…ç½®å·²åŠ è½½",
                    interactive=False
                )

                def refresh_config():
                    return engine.get_config_summary(), "é…ç½®å·²åˆ·æ–°"

                def reload_config():
                    engine.config = engine.load_config()
                    engine.initialize_real_components()  # é‡æ–°åˆå§‹åŒ–ç»„ä»¶
                    return engine.get_config_summary(), "é…ç½®æ–‡ä»¶å·²é‡æ–°åŠ è½½ï¼Œç»„ä»¶å·²é‡æ–°åˆå§‹åŒ–"

                refresh_config_btn.click(
                    refresh_config,
                    outputs=[config_display, config_status]
                )

                reload_config_btn.click(
                    reload_config,
                    outputs=[config_display, config_status]
                )

            # æ™ºèƒ½æ£€ç´¢æ ‡ç­¾é¡µ
            with gr.Tab("ğŸ” æ™ºèƒ½æ£€ç´¢"):
                gr.HTML("<h2>ğŸ§  æ™ºèƒ½æŸ¥è¯¢å¤„ç†</h2>")

                # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„ç»„ä»¶ç±»å‹
                component_status = gr.HTML(
                    value=f"<div style='padding: 10px; background: {'#d4edda' if engine.use_real_components else '#fff3cd'}; border-radius: 5px; margin-bottom: 10px;'>"
                          f"<strong>å½“å‰çŠ¶æ€</strong>: {'âœ… ä½¿ç”¨çœŸå®ç»„ä»¶' if engine.use_real_components else 'âš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿç»„ä»¶'}</div>"
                )

                with gr.Row():
                    with gr.Column(scale=2):
                        query_input = gr.Textbox(
                            label="è¾“å…¥æŸ¥è¯¢",
                            placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
                            lines=3
                        )

                        with gr.Row():
                            process_btn = gr.Button("ğŸš€ å¤„ç†æŸ¥è¯¢", variant="primary")
                            clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º", variant="secondary")

                        show_details = gr.Checkbox(
                            label="æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯",
                            value=True
                        )

                    with gr.Column(scale=1):
                        gr.HTML("<h4>ğŸ“Š å¿«é€Ÿç»Ÿè®¡</h4>")
                        query_stats = gr.JSON(
                            label="æŸ¥è¯¢ç»Ÿè®¡",
                            value={"æ€»æŸ¥è¯¢æ•°": 0, "å¹³å‡å¤„ç†æ—¶é—´": "0.0s", "ä½¿ç”¨çœŸå®ç»„ä»¶": engine.use_real_components}
                        )

                # ç»“æœå±•ç¤ºåŒºåŸŸ
                with gr.Row():
                    with gr.Column():
                        gr.HTML("<h3>ğŸ“ˆ å¤„ç†æµç¨‹</h3>")
                        process_flow = gr.JSON(label="å¤„ç†é˜¶æ®µè¯¦æƒ…")

                    with gr.Column():
                        gr.HTML("<h3>ğŸ’¬ ç”Ÿæˆç»“æœ</h3>")
                        generated_answer = gr.Textbox(
                            label="ç”Ÿæˆçš„ç­”æ¡ˆ",
                            lines=5,
                            interactive=False
                        )

                # æ£€ç´¢ç»“æœå±•ç¤º
                with gr.Row():
                    gr.HTML("<h3>ğŸ“š æ£€ç´¢ç»“æœ</h3>")

                retrieved_docs = gr.JSON(label="æ£€ç´¢åˆ°çš„æ–‡æ¡£")

                def process_query(query, show_details_flag):
                    if not query.strip():
                        return {}, "è¯·è¾“å…¥æœ‰æ•ˆçš„æŸ¥è¯¢", {}

                    result = engine.process_query(query, show_details_flag)

                    # æå–å¤„ç†æµç¨‹ä¿¡æ¯
                    flow_info = {}
                    for stage_name, stage_data in result["stages"].items():
                        flow_info[stage_name] = {
                            "å¤„ç†æ—¶é—´": f"{stage_data.get('processing_time', 0):.3f}s",
                            "çŠ¶æ€": stage_data.get('status', 'âœ… å®Œæˆ')
                        }

                    flow_info["æ€»å¤„ç†æ—¶é—´"] = f"{result['total_time']:.3f}s"
                    flow_info["å¤„ç†æ–¹æ³•"] = result.get('method', 'unknown')

                    # æå–ç”Ÿæˆçš„ç­”æ¡ˆ
                    answer = result.get("answer", "")

                    # æå–æ£€ç´¢ç»“æœ
                    docs = result.get("retrieved_docs", {})

                    return flow_info, answer, docs

                def clear_inputs():
                    return "", {}, "", {}

                process_btn.click(
                    process_query,
                    inputs=[query_input, show_details],
                    outputs=[process_flow, generated_answer, retrieved_docs]
                )

                clear_btn.click(
                    clear_inputs,
                    outputs=[query_input, process_flow, generated_answer, retrieved_docs]
                )

            # ç»“æœåˆ†ææ ‡ç­¾é¡µ
            with gr.Tab("ğŸ“ˆ ç»“æœåˆ†æ"):
                gr.HTML("<h2>ğŸ“Š æ€§èƒ½åˆ†æä¸å¯è§†åŒ–</h2>")

                with gr.Row():
                    with gr.Column():
                        gr.HTML("<h3>â±ï¸ æ€§èƒ½æŒ‡æ ‡</h3>")
                        performance_stats = gr.JSON(
                            label="æ€§èƒ½ç»Ÿè®¡",
                            value={
                                "å¹³å‡æŸ¥è¯¢åˆ†ææ—¶é—´": "0.1s",
                                "å¹³å‡æ£€ç´¢æ—¶é—´": "0.2s",
                                "å¹³å‡ç”Ÿæˆæ—¶é—´": "0.3s",
                                "æ€»å¹³å‡æ—¶é—´": "0.7s",
                                "ç»„ä»¶ç±»å‹": "çœŸå®ç»„ä»¶" if engine.use_real_components else "æ¨¡æ‹Ÿç»„ä»¶"
                            }
                        )

                    with gr.Column():
                        gr.HTML("<h3>ğŸ¯ å‡†ç¡®æ€§æŒ‡æ ‡</h3>")
                        accuracy_stats = gr.JSON(
                            label="å‡†ç¡®æ€§ç»Ÿè®¡",
                            value={
                                "æ£€ç´¢å‡†ç¡®ç‡": "85%",
                                "ç”Ÿæˆè´¨é‡": "88%",
                                "ç”¨æˆ·æ»¡æ„åº¦": "90%",
                                "çœŸå®ç»„ä»¶ä½¿ç”¨ç‡": "100%" if engine.use_real_components else "0%"
                            }
                        )

                with gr.Row():
                    gr.HTML("<h3>ğŸ“‹ æœ€è¿‘æŸ¥è¯¢å†å²</h3>")

                query_history = gr.Dataframe(
                    headers=["æ—¶é—´", "æŸ¥è¯¢", "å¤„ç†æ—¶é—´", "æ–¹æ³•", "çŠ¶æ€"],
                    datatype=["str", "str", "str", "str", "str"],
                    label="æŸ¥è¯¢å†å²"
                )

    return demo

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="å¯åŠ¨ AdaptiveRAG WebUI (çœŸå®å®ç°ç‰ˆ)")
    parser.add_argument("--port", type=int, default=7861, help="æœåŠ¡ç«¯å£")
    parser.add_argument("--host", type=str, default="0.0.0.0", help="æœåŠ¡ä¸»æœº")
    parser.add_argument("--config-path", type=str, default="real_config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--debug", action="store_true", help="è°ƒè¯•æ¨¡å¼")
    parser.add_argument("--share", action="store_true", help="åˆ›å»ºå…¬å…±é“¾æ¥")

    args = parser.parse_args()

    logger.info("ğŸš€ å¯åŠ¨ AdaptiveRAG WebUI (çœŸå®å®ç°ç‰ˆ)")
    logger.info(f"ğŸ“ åœ°å€: http://{args.host}:{args.port}")
    logger.info(f"ğŸ“ é…ç½®æ–‡ä»¶: {args.config_path}")
    logger.info(f"ğŸ”§ è°ƒè¯•æ¨¡å¼: {args.debug}")

    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not Path(args.config_path).exists():
        logger.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config_path}")
        return

    # åˆ›å»ºå¹¶å¯åŠ¨ WebUI
    demo = create_webui(args.config_path)

    try:
        demo.launch(
            server_name=args.host,
            server_port=args.port,
            share=args.share,
            debug=args.debug,
            show_error=True,
            quiet=False
        )
    except OSError as e:
        if "Cannot find empty port" in str(e):
            logger.error(f"âŒ ç«¯å£ {args.port} è¢«å ç”¨")
            logger.info(f"ğŸ’¡ å°è¯•ä½¿ç”¨å…¶ä»–ç«¯å£:")

            # è‡ªåŠ¨å°è¯•å…¶ä»–ç«¯å£
            for port in range(args.port + 1, args.port + 10):
                try:
                    logger.info(f"ğŸ”„ å°è¯•ç«¯å£ {port}...")
                    demo.launch(
                        server_name=args.host,
                        server_port=port,
                        share=args.share,
                        debug=args.debug,
                        show_error=True,
                        quiet=False
                    )
                    break
                except OSError:
                    continue
            else:
                logger.error(f"âŒ æ— æ³•æ‰¾åˆ°å¯ç”¨ç«¯å£ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šç«¯å£")
        else:
            raise e

if __name__ == "__main__":
    main()