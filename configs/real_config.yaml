# ===== AdaptiveRAG 真实配置文件 =====
# 使用真实的检索器、生成器和数据，而不是模拟实现

# ------------------------------------------------环境设置------------------------------------------------#
device: "cuda"
gpu_id: "0"
seed: 2024
batch_size: 4
debug_mode: false
log_level: "INFO"

# ------------------------------------------------路径设置------------------------------------------------#
data_dir: "/root/autodl-tmp/test_data"
save_dir: "/root/autodl-tmp/test_results"
models_dir: "/root/autodl-tmp/models"

# 语料库和索引路径
corpus_path: "/root/autodl-tmp/test_data/test_corpus.jsonl"
index_path: "/root/my_project/adaptiverag/adaptive_rag/data/e5_Flat.index"

# ------------------------------------------------数据集设置------------------------------------------------#
dataset_name: "hotpotqa"
split: ["test"]
test_sample_num: 5  # 使用小数据集测试
random_sample: false

# ------------------------------------------------检索器配置------------------------------------------------#
# 真实的检索器配置，不再使用 mock
retriever_configs:
  dense_retriever:
    retriever_type: "dense"  # 真实类型
    model_name: "intfloat/e5-base-v2"
    model_path: "/root/autodl-tmp/models/e5-base-v2"
    index_path: "/root/my_project/adaptiverag/adaptive_rag/data/e5_Flat.index"
    corpus_path: "/root/autodl-tmp/test_data/test_corpus.jsonl"
    top_k: 10
    batch_size: 32
    device: "cuda"
    
  keyword_retriever:
    retriever_type: "bm25"  # 改为真实类型
    corpus_path: "/root/autodl-tmp/test_data/test_corpus.jsonl"
    top_k: 10
    backend: "bm25s"
    
  web_retriever:
    retriever_type: "mock"  # 暂时保持模拟，因为需要API
    search_engine: "duckduckgo"

# ------------------------------------------------重排序器配置------------------------------------------------#
ranker_configs:
  cross_encoder:
    ranker_type: "cross_encoder"  # 真实类型
    model_name: "BAAI/bge-reranker-base"
    model_path: "/root/autodl-tmp/models/bge-reranker-base"
    top_k: 5
    batch_size: 16
    device: "cuda"

# ------------------------------------------------生成器配置------------------------------------------------#
generator_configs:
  main_generator:
    generator_type: "hf"  # 真实类型
    model_name: "Qwen/Qwen1.5-1.8B-Chat"
    model_path: "/root/autodl-tmp/models/Qwen1.5-1.8B-Chat"
    device: "cuda"
    max_memory: "8GB"
    
  # 备用生成器（如果主生成器失败）
  fallback_generator:
    generator_type: "mock"
    model_name: "fallback"

# ------------------------------------------------编码器配置------------------------------------------------#
encoder_configs:
  dense_encoder:
    encoder_type: "sentence_transformer"
    model_name: "intfloat/e5-base-v2"
    model_path: "/root/autodl-tmp/models/e5-base-v2"
    device: "cuda"
    pooling_method: "mean"

# ------------------------------------------------检索策略配置------------------------------------------------#
retrieval_strategy:
  # 检索参数
  retrieval_topk: 10
  final_context_count: 5
  
  # 任务类型特定权重
  task_specific_weights:
    factual:
      keyword: 0.7
      dense: 0.2
      web: 0.1
    semantic:
      keyword: 0.2
      dense: 0.7
      web: 0.1
    multi_hop:
      keyword: 0.3
      dense: 0.5
      web: 0.2
    comparative:
      keyword: 0.4
      dense: 0.4
      web: 0.2

# ------------------------------------------------生成配置------------------------------------------------#
generation_params:
  max_tokens: 256
  temperature: 0.1
  top_p: 0.9
  do_sample: false
  repetition_penalty: 1.1

# ------------------------------------------------AdaptiveRAG 特定设置------------------------------------------------#
adaptive_retrieval:
  enable_task_decomposition: true
  enable_strategy_planning: true
  enable_multi_retriever: true
  enable_reranking: true

# 任务分解配置
task_decomposition:
  max_subtasks: 3
  decomposition_threshold: 0.7
  enable_entity_extraction: true

# 策略规划配置
strategy_planning:
  enable_dynamic_weights: true
  confidence_threshold: 0.8
  
# 重排序配置
reranking:
  enable_reranking: true
  rerank_topk: 5
  diversity_threshold: 0.85

# ------------------------------------------------评估设置------------------------------------------------#
metrics: ["exact_match", "f1_score", "rouge_l"]
compute_bert_score: false  # 暂时关闭，避免额外依赖

# ------------------------------------------------保存设置------------------------------------------------#
save_intermediate_data: true
save_predictions: true
save_note: "real_adaptive_rag_experiment"

# ------------------------------------------------性能优化设置------------------------------------------------#
performance_optimization:
  enable_caching: true
  cache_size: 1000
  enable_batch_processing: true
  enable_gpu_acceleration: true

# ------------------------------------------------模型下载设置------------------------------------------------#
model_download:
  # 是否自动下载缺失的模型
  auto_download: true
  # 下载目录
  download_dir: "/root/autodl-tmp/models"
  # 使用镜像加速
  use_mirror: true
  mirror_url: "https://hf-mirror.com"
