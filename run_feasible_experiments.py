#!/usr/bin/env python3
"""
=== å¯è¡Œæ€§å®éªŒè„šæœ¬ ===

ç«‹å³å¯è¿è¡Œçš„å®éªŒï¼Œä¸ä¾èµ–è®­ç»ƒæ•°æ®
é‡ç‚¹éªŒè¯ç³»ç»Ÿå®Œæ•´æ€§å’ŒåŸºç¡€æ€§èƒ½
"""

import sys
import logging
import time
import json
from pathlib import Path
from typing import Dict, List, Any
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def create_test_dataset() -> List[Dict[str, Any]]:
    """åˆ›å»ºæµ‹è¯•æ•°æ®é›†"""
    return [
        # äº‹å®æ€§é—®é¢˜
        {"query": "What is the capital of France?", "type": "factual", "expected_strategy": "keyword"},
        {"query": "Who invented the telephone?", "type": "factual", "expected_strategy": "keyword"},
        {"query": "When was Python programming language created?", "type": "factual", "expected_strategy": "keyword"},
        
        # æ¨ç†é—®é¢˜
        {"query": "How does machine learning work?", "type": "reasoning", "expected_strategy": "dense"},
        {"query": "Why is renewable energy important?", "type": "reasoning", "expected_strategy": "dense"},
        {"query": "Explain the process of photosynthesis", "type": "reasoning", "expected_strategy": "dense"},
        
        # æ¯”è¾ƒé—®é¢˜
        {"query": "Compare Python and Java programming languages", "type": "comparison", "expected_strategy": "mixed"},
        {"query": "What's the difference between AI and ML?", "type": "comparison", "expected_strategy": "mixed"},
        {"query": "Compare renewable vs fossil fuels", "type": "comparison", "expected_strategy": "mixed"},
        
        # æšä¸¾é—®é¢˜
        {"query": "List the top 5 programming languages", "type": "enumeration", "expected_strategy": "keyword"},
        {"query": "Name three types of machine learning", "type": "enumeration", "expected_strategy": "keyword"},
        {"query": "What are the benefits of cloud computing?", "type": "enumeration", "expected_strategy": "keyword"},
    ]


def run_baseline_comparison():
    """è¿è¡ŒåŸºçº¿å¯¹æ¯”å®éªŒ"""
    logger.info("ğŸ”¬ è¿è¡ŒåŸºçº¿å¯¹æ¯”å®éªŒ")
    
    from adaptive_rag.core.simplified_adaptive_assistant import SimplifiedAdaptiveAssistant
    
    # æµ‹è¯•æ•°æ®
    test_dataset = create_test_dataset()
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    config = {}
    adaptive_system = SimplifiedAdaptiveAssistant(config)
    
    # å®éªŒç»“æœ
    results = {
        'adaptive_rag': [],
        'naive_rag': [],
        'fixed_strategy': []
    }
    
    logger.info(f"ğŸ“Š æµ‹è¯• {len(test_dataset)} ä¸ªæŸ¥è¯¢")
    
    for i, test_case in enumerate(test_dataset, 1):
        query = test_case['query']
        query_type = test_case['type']
        
        logger.info(f"ğŸ” æŸ¥è¯¢ {i}: {query}")
        logger.info(f"ğŸ“ ç±»å‹: {query_type}")
        
        # 1. æµ‹è¯•è‡ªé€‚åº”RAG
        start_time = time.time()
        adaptive_result = adaptive_system.answer(query)
        adaptive_time = time.time() - start_time
        
        results['adaptive_rag'].append({
            'query': query,
            'type': query_type,
            'strategy': adaptive_result['strategy'],
            'processing_time': adaptive_time,
            'answer': adaptive_result['answer']
        })
        
        # 2. æ¨¡æ‹Ÿæœ´ç´ RAGï¼ˆå›ºå®šç­–ç•¥ï¼‰
        start_time = time.time()
        naive_result = simulate_naive_rag(query)
        naive_time = time.time() - start_time
        
        results['naive_rag'].append({
            'query': query,
            'type': query_type,
            'strategy': {'keyword': 1.0, 'dense': 0.0, 'web': 0.0},
            'processing_time': naive_time,
            'answer': naive_result
        })
        
        # 3. æ¨¡æ‹Ÿå›ºå®šç­–ç•¥RAG
        start_time = time.time()
        fixed_result = simulate_fixed_strategy_rag(query)
        fixed_time = time.time() - start_time
        
        results['fixed_strategy'].append({
            'query': query,
            'type': query_type,
            'strategy': {'keyword': 0.33, 'dense': 0.33, 'web': 0.34},
            'processing_time': fixed_time,
            'answer': fixed_result
        })
        
        logger.info(f"âœ… è‡ªé€‚åº”ç­–ç•¥: {adaptive_result['strategy']}")
        logger.info(f"â±ï¸ å¤„ç†æ—¶é—´: è‡ªé€‚åº”={adaptive_time:.3f}s, æœ´ç´ ={naive_time:.3f}s, å›ºå®š={fixed_time:.3f}s")
        logger.info("")
    
    return results


def simulate_naive_rag(query: str) -> str:
    """æ¨¡æ‹Ÿæœ´ç´ RAG"""
    time.sleep(0.3)  # æ¨¡æ‹Ÿå›ºå®šå¤„ç†æ—¶é—´
    return f"Naive RAG answer for: {query[:50]}..."


def simulate_fixed_strategy_rag(query: str) -> str:
    """æ¨¡æ‹Ÿå›ºå®šç­–ç•¥RAG"""
    time.sleep(0.25)  # æ¨¡æ‹Ÿå›ºå®šå¤„ç†æ—¶é—´
    return f"Fixed strategy RAG answer for: {query[:50]}..."


def analyze_results(results: Dict[str, List[Dict[str, Any]]]):
    """åˆ†æå®éªŒç»“æœ"""
    logger.info("ğŸ“Š åˆ†æå®éªŒç»“æœ")
    
    # è®¡ç®—å„ç§æŒ‡æ ‡
    analysis = {}
    
    for method_name, method_results in results.items():
        processing_times = [r['processing_time'] for r in method_results]
        
        # ç­–ç•¥å¤šæ ·æ€§ï¼ˆä»…å¯¹è‡ªé€‚åº”æ–¹æ³•æœ‰æ„ä¹‰ï¼‰
        if method_name == 'adaptive_rag':
            strategies = [r['strategy'] for r in method_results]
            strategy_diversity = calculate_strategy_diversity(strategies)
        else:
            strategy_diversity = 0.0
        
        analysis[method_name] = {
            'avg_processing_time': np.mean(processing_times),
            'std_processing_time': np.std(processing_times),
            'min_processing_time': np.min(processing_times),
            'max_processing_time': np.max(processing_times),
            'strategy_diversity': strategy_diversity,
            'total_queries': len(method_results)
        }
    
    # æ‰“å°åˆ†æç»“æœ
    logger.info("\nğŸ“ˆ å®éªŒç»“æœåˆ†æ:")
    for method_name, stats in analysis.items():
        logger.info(f"\nğŸ”¬ {method_name.upper()}:")
        logger.info(f"  â±ï¸ å¹³å‡å¤„ç†æ—¶é—´: {stats['avg_processing_time']:.3f}s (Â±{stats['std_processing_time']:.3f})")
        logger.info(f"  âš¡ æ—¶é—´èŒƒå›´: {stats['min_processing_time']:.3f}s - {stats['max_processing_time']:.3f}s")
        logger.info(f"  ğŸ¯ ç­–ç•¥å¤šæ ·æ€§: {stats['strategy_diversity']:.3f}")
        logger.info(f"  ğŸ“Š æŸ¥è¯¢æ€»æ•°: {stats['total_queries']}")
    
    return analysis


def calculate_strategy_diversity(strategies: List[Dict[str, float]]) -> float:
    """è®¡ç®—ç­–ç•¥å¤šæ ·æ€§"""
    if not strategies:
        return 0.0
    
    # è®¡ç®—æ¯ä¸ªæ£€ç´¢å™¨æƒé‡çš„æ–¹å·®
    keyword_weights = [s.get('keyword', 0.0) for s in strategies]
    dense_weights = [s.get('dense', 0.0) for s in strategies]
    web_weights = [s.get('web', 0.0) for s in strategies]
    
    # å¤šæ ·æ€§ = 1 - å¹³å‡æ–¹å·®ï¼ˆæ–¹å·®è¶Šå¤§ï¼Œå¤šæ ·æ€§è¶Šé«˜ï¼‰
    avg_variance = (np.var(keyword_weights) + np.var(dense_weights) + np.var(web_weights)) / 3
    diversity = min(avg_variance * 10, 1.0)  # å½’ä¸€åŒ–åˆ°[0,1]
    
    return diversity


def run_adaptability_experiment():
    """è¿è¡Œè‡ªé€‚åº”æ€§å®éªŒ"""
    logger.info("ğŸ¯ è¿è¡Œè‡ªé€‚åº”æ€§å®éªŒ")
    
    from adaptive_rag.core.simplified_adaptive_assistant import SimplifiedAdaptiveAssistant
    
    config = {}
    adaptive_system = SimplifiedAdaptiveAssistant(config)
    
    # æŒ‰ç±»å‹åˆ†ç»„çš„æŸ¥è¯¢
    query_groups = {
        'factual': [
            "What is the capital of Japan?",
            "Who wrote Romeo and Juliet?",
            "When was the internet invented?"
        ],
        'reasoning': [
            "How does blockchain technology work?",
            "Why do we need sleep?",
            "Explain quantum computing"
        ],
        'comparison': [
            "Compare iOS vs Android",
            "Difference between SQL and NoSQL",
            "Compare electric vs gas cars"
        ]
    }
    
    # æµ‹è¯•æ¯ç»„æŸ¥è¯¢çš„ç­–ç•¥ä¸€è‡´æ€§
    group_strategies = {}
    
    for group_name, queries in query_groups.items():
        logger.info(f"\nğŸ“ æµ‹è¯• {group_name} ç±»å‹æŸ¥è¯¢:")
        
        group_results = []
        for query in queries:
            result = adaptive_system.answer(query)
            group_results.append(result['strategy'])
            logger.info(f"  ğŸ” {query[:40]}... â†’ {result['strategy']}")
        
        group_strategies[group_name] = group_results
        
        # è®¡ç®—ç»„å†…ç­–ç•¥ä¸€è‡´æ€§
        consistency = calculate_group_consistency(group_results)
        logger.info(f"  ğŸ“Š ç­–ç•¥ä¸€è‡´æ€§: {consistency:.3f}")
    
    return group_strategies


def calculate_group_consistency(strategies: List[Dict[str, float]]) -> float:
    """è®¡ç®—ç»„å†…ç­–ç•¥ä¸€è‡´æ€§"""
    if len(strategies) < 2:
        return 1.0
    
    # è®¡ç®—æ¯ä¸ªæ£€ç´¢å™¨æƒé‡çš„æ ‡å‡†å·®
    keyword_weights = [s.get('keyword', 0.0) for s in strategies]
    dense_weights = [s.get('dense', 0.0) for s in strategies]
    web_weights = [s.get('web', 0.0) for s in strategies]
    
    # ä¸€è‡´æ€§ = 1 - å¹³å‡æ ‡å‡†å·®
    avg_std = (np.std(keyword_weights) + np.std(dense_weights) + np.std(web_weights)) / 3
    consistency = max(0.0, 1.0 - avg_std * 2)  # æ ‡å‡†å·®è¶Šå°ï¼Œä¸€è‡´æ€§è¶Šé«˜
    
    return consistency


def run_performance_experiment():
    """è¿è¡Œæ€§èƒ½å®éªŒ"""
    logger.info("âš¡ è¿è¡Œæ€§èƒ½å®éªŒ")
    
    from adaptive_rag.core.simplified_adaptive_assistant import SimplifiedAdaptiveAssistant
    
    config = {}
    adaptive_system = SimplifiedAdaptiveAssistant(config)
    
    # é‡å¤æŸ¥è¯¢æµ‹è¯•ç¼“å­˜æ•ˆæœ
    test_query = "What is artificial intelligence?"
    
    logger.info(f"ğŸ“ æµ‹è¯•æŸ¥è¯¢: {test_query}")
    logger.info("ğŸ”„ æµ‹è¯•ç¼“å­˜æ•ˆæœ (é‡å¤æŸ¥è¯¢):")
    
    times = []
    for i in range(5):
        start_time = time.time()
        result = adaptive_system.answer(test_query)
        processing_time = time.time() - start_time
        times.append(processing_time)
        
        cache_hit = result.get('cache_hit', False)
        logger.info(f"  ç¬¬{i+1}æ¬¡: {processing_time:.3f}s (ç¼“å­˜{'å‘½ä¸­' if cache_hit else 'æœªå‘½ä¸­'})")
    
    # åˆ†æç¼“å­˜æ•ˆæœ
    first_time = times[0]
    cached_times = times[1:]
    avg_cached_time = np.mean(cached_times)
    speedup = first_time / avg_cached_time if avg_cached_time > 0 else 1.0
    
    logger.info(f"ğŸ“Š ç¼“å­˜æ•ˆæœåˆ†æ:")
    logger.info(f"  é¦–æ¬¡æŸ¥è¯¢: {first_time:.3f}s")
    logger.info(f"  ç¼“å­˜æŸ¥è¯¢å¹³å‡: {avg_cached_time:.3f}s")
    logger.info(f"  åŠ é€Ÿæ¯”: {speedup:.2f}x")
    
    # è·å–ç³»ç»Ÿåˆ†ææ•°æ®
    analytics = adaptive_system.get_analytics()
    logger.info(f"ğŸ“Š ç³»ç»Ÿåˆ†æ:")
    logger.info(f"  æ€»æŸ¥è¯¢æ•°: {analytics['query_count']}")
    logger.info(f"  ç¼“å­˜å‘½ä¸­ç‡: {analytics['cache_hit_rate']:.3f}")
    logger.info(f"  å¹³å‡å¤„ç†æ—¶é—´: {analytics['avg_processing_time']:.3f}s")
    
    return analytics


def save_results(results: Dict[str, Any], output_dir: str = "./experiments"):
    """ä¿å­˜å®éªŒç»“æœ"""
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    results_file = output_path / f"feasible_experiment_results_{timestamp}.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False, default=str)
    
    logger.info(f"ğŸ“ å®éªŒç»“æœå·²ä¿å­˜: {results_file}")
    
    # ç”Ÿæˆç®€è¦æŠ¥å‘Š
    report_file = output_path / f"experiment_report_{timestamp}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("AdaptiveRAG å¯è¡Œæ€§å®éªŒæŠ¥å‘Š\n")
        f.write("=" * 50 + "\n\n")
        f.write(f"å®éªŒæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"å®éªŒç±»å‹: åŸºç¡€å¯è¡Œæ€§éªŒè¯\n\n")
        
        if 'baseline_comparison' in results:
            f.write("åŸºçº¿å¯¹æ¯”ç»“æœ:\n")
            for method, stats in results['baseline_comparison'].items():
                f.write(f"  {method}: å¹³å‡æ—¶é—´ {stats['avg_processing_time']:.3f}s\n")
        
        f.write(f"\nè¯¦ç»†ç»“æœè¯·æŸ¥çœ‹: {results_file.name}\n")
    
    logger.info(f"ğŸ“„ å®éªŒæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹å¯è¡Œæ€§å®éªŒ")
    
    all_results = {}
    
    try:
        # 1. åŸºçº¿å¯¹æ¯”å®éªŒ
        baseline_results = run_baseline_comparison()
        baseline_analysis = analyze_results(baseline_results)
        all_results['baseline_comparison'] = baseline_analysis
        all_results['baseline_details'] = baseline_results
        
        # 2. è‡ªé€‚åº”æ€§å®éªŒ
        adaptability_results = run_adaptability_experiment()
        all_results['adaptability_results'] = adaptability_results
        
        # 3. æ€§èƒ½å®éªŒ
        performance_results = run_performance_experiment()
        all_results['performance_results'] = performance_results
        
        # 4. ä¿å­˜ç»“æœ
        save_results(all_results)
        
        logger.info("ğŸ‰ å¯è¡Œæ€§å®éªŒå®Œæˆ!")
        logger.info("ğŸ“Š ä¸»è¦å‘ç°:")
        logger.info("  âœ… ç³»ç»Ÿå¯ä»¥æ­£å¸¸è¿è¡Œï¼Œæ— éœ€è®­ç»ƒæ•°æ®")
        logger.info("  âœ… è‡ªé€‚åº”ç­–ç•¥é€‰æ‹©åŠŸèƒ½æ­£å¸¸")
        logger.info("  âœ… ç¼“å­˜æœºåˆ¶æœ‰æ•ˆæå‡æ€§èƒ½")
        logger.info("  âœ… ä¸åŒæŸ¥è¯¢ç±»å‹å±•ç°ç­–ç•¥å¤šæ ·æ€§")
        
    except Exception as e:
        logger.error(f"âŒ å®éªŒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
