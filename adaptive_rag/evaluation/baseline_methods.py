#!/usr/bin/env python3
"""
=== åŸºçº¿æ–¹æ³•å®ç° ===

å®ç° FlashRAG ä¸­çš„ä¸»è¦åŸºçº¿æ–¹æ³•ï¼Œç”¨äºä¸ AdaptiveRAG å¯¹æ¯”
"""

import time
import logging
from typing import Dict, List, Any, Optional
from abc import ABC, abstractmethod

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class BaseRAGMethod(ABC):
    """RAG æ–¹æ³•åŸºç±»"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.method_name = self.__class__.__name__
    
    @abstractmethod
    def process_query(self, question: str) -> Dict[str, Any]:
        """
        å¤„ç†æŸ¥è¯¢
        
        Args:
            question: è¾“å…¥é—®é¢˜
            
        Returns:
            Dict: åŒ…å«ç­”æ¡ˆå’Œæ—¶é—´ä¿¡æ¯çš„ç»“æœ
        """
        pass
    
    def _measure_time(self, func, *args, **kwargs):
        """æµ‹é‡å‡½æ•°æ‰§è¡Œæ—¶é—´"""
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        return result, end_time - start_time


class NaiveRAG(BaseRAGMethod):
    """æœ´ç´  RAG æ–¹æ³• - ç®€å•æ£€ç´¢ + ç”Ÿæˆ"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.retrieval_topk = config.get("retrieval_topk", 5)
        self.max_tokens = config.get("max_tokens", 256)
        
        # æ¨¡æ‹Ÿç»„ä»¶åˆå§‹åŒ–
        logger.info(f"ğŸ”§ åˆå§‹åŒ– Naive RAG (topk={self.retrieval_topk})")
    
    def process_query(self, question: str) -> Dict[str, Any]:
        """å¤„ç†æŸ¥è¯¢ - ç®€å•æ£€ç´¢ + ç”Ÿæˆ"""
        
        # 1. æ£€ç´¢é˜¶æ®µ
        retrieval_result, retrieval_time = self._measure_time(self._retrieve, question)
        
        # 2. ç”Ÿæˆé˜¶æ®µ
        generation_result, generation_time = self._measure_time(
            self._generate, question, retrieval_result
        )
        
        return {
            "answer": generation_result,
            "retrieval_time": retrieval_time,
            "generation_time": generation_time,
            "retrieved_docs": retrieval_result,
            "method": "naive_rag"
        }
    
    def _retrieve(self, question: str) -> List[str]:
        """æ¨¡æ‹Ÿæ£€ç´¢è¿‡ç¨‹"""
        # æ¨¡æ‹Ÿæ£€ç´¢å»¶è¿Ÿ
        time.sleep(0.1)
        
        # è¿”å›æ¨¡æ‹Ÿæ£€ç´¢ç»“æœ
        return [
            f"Retrieved document {i+1} for question: {question[:50]}..."
            for i in range(self.retrieval_topk)
        ]
    
    def _generate(self, question: str, contexts: List[str]) -> str:
        """æ¨¡æ‹Ÿç”Ÿæˆè¿‡ç¨‹"""
        # æ¨¡æ‹Ÿç”Ÿæˆå»¶è¿Ÿ
        time.sleep(0.2)
        
        # è¿”å›æ¨¡æ‹Ÿç­”æ¡ˆ
        return f"Naive RAG answer for: {question[:30]}... (based on {len(contexts)} docs)"


class SelfRAG(BaseRAGMethod):
    """Self-RAG æ–¹æ³• - è‡ªæˆ‘åæ€çš„ RAG"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.retrieval_topk = config.get("retrieval_topk", 5)
        self.max_iterations = config.get("max_iterations", 3)
        self.reflection_threshold = config.get("reflection_threshold", 0.7)
        
        logger.info(f"ğŸ”§ åˆå§‹åŒ– Self-RAG (topk={self.retrieval_topk}, max_iter={self.max_iterations})")
    
    def process_query(self, question: str) -> Dict[str, Any]:
        """å¤„ç†æŸ¥è¯¢ - å¸¦è‡ªæˆ‘åæ€çš„æ£€ç´¢ç”Ÿæˆ"""
        
        total_retrieval_time = 0.0
        total_generation_time = 0.0
        all_retrieved_docs = []
        
        # åˆå§‹æ£€ç´¢
        retrieval_result, retrieval_time = self._measure_time(self._retrieve, question)
        total_retrieval_time += retrieval_time
        all_retrieved_docs.extend(retrieval_result)
        
        # è¿­ä»£ç”Ÿæˆå’Œåæ€
        for iteration in range(self.max_iterations):
            # ç”Ÿæˆç­”æ¡ˆ
            generation_result, generation_time = self._measure_time(
                self._generate, question, retrieval_result
            )
            total_generation_time += generation_time
            
            # è‡ªæˆ‘åæ€
            reflection_result, reflection_time = self._measure_time(
                self._reflect, question, generation_result, retrieval_result
            )
            total_generation_time += reflection_time
            
            # å¦‚æœåæ€åˆ†æ•°è¶³å¤Ÿé«˜ï¼Œåœæ­¢è¿­ä»£
            if reflection_result["confidence"] >= self.reflection_threshold:
                break
            
            # å¦åˆ™è¿›è¡Œé¢å¤–æ£€ç´¢
            if iteration < self.max_iterations - 1:
                additional_docs, additional_time = self._measure_time(
                    self._retrieve_additional, question, generation_result
                )
                total_retrieval_time += additional_time
                retrieval_result.extend(additional_docs)
                all_retrieved_docs.extend(additional_docs)
        
        return {
            "answer": generation_result,
            "retrieval_time": total_retrieval_time,
            "generation_time": total_generation_time,
            "retrieved_docs": all_retrieved_docs,
            "iterations": iteration + 1,
            "final_confidence": reflection_result["confidence"],
            "method": "self_rag"
        }
    
    def _retrieve(self, question: str) -> List[str]:
        """æ¨¡æ‹Ÿæ£€ç´¢è¿‡ç¨‹"""
        time.sleep(0.1)
        return [
            f"Self-RAG retrieved doc {i+1} for: {question[:50]}..."
            for i in range(self.retrieval_topk)
        ]
    
    def _retrieve_additional(self, question: str, previous_answer: str) -> List[str]:
        """æ¨¡æ‹Ÿé¢å¤–æ£€ç´¢"""
        time.sleep(0.05)
        return [
            f"Additional doc based on answer: {previous_answer[:30]}..."
            for _ in range(2)
        ]
    
    def _generate(self, question: str, contexts: List[str]) -> str:
        """æ¨¡æ‹Ÿç”Ÿæˆè¿‡ç¨‹"""
        time.sleep(0.2)
        return f"Self-RAG answer for: {question[:30]}... (iteration with {len(contexts)} docs)"
    
    def _reflect(self, question: str, answer: str, contexts: List[str]) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿè‡ªæˆ‘åæ€è¿‡ç¨‹"""
        time.sleep(0.1)
        
        # æ¨¡æ‹Ÿç½®ä¿¡åº¦è®¡ç®—
        import random
        confidence = random.uniform(0.5, 1.0)
        
        return {
            "confidence": confidence,
            "needs_more_info": confidence < self.reflection_threshold,
            "reflection_score": confidence
        }


class RAPTOR(BaseRAGMethod):
    """RAPTOR æ–¹æ³• - é€’å½’æŠ½è±¡å¤„ç†çš„ RAG"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.tree_depth = config.get("tree_depth", 3)
        self.cluster_size = config.get("cluster_size", 5)
        
        logger.info(f"ğŸ”§ åˆå§‹åŒ– RAPTOR (depth={self.tree_depth}, cluster_size={self.cluster_size})")
    
    def process_query(self, question: str) -> Dict[str, Any]:
        """å¤„ç†æŸ¥è¯¢ - å±‚æ¬¡åŒ–æ£€ç´¢"""
        
        # 1. æ„å»ºæ–‡æ¡£æ ‘
        tree_result, tree_time = self._measure_time(self._build_document_tree, question)
        
        # 2. å±‚æ¬¡åŒ–æ£€ç´¢
        retrieval_result, retrieval_time = self._measure_time(
            self._hierarchical_retrieve, question, tree_result
        )
        
        # 3. ç”Ÿæˆç­”æ¡ˆ
        generation_result, generation_time = self._measure_time(
            self._generate, question, retrieval_result
        )
        
        return {
            "answer": generation_result,
            "retrieval_time": retrieval_time + tree_time,
            "generation_time": generation_time,
            "retrieved_docs": retrieval_result,
            "tree_depth": self.tree_depth,
            "method": "raptor"
        }
    
    def _build_document_tree(self, question: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæ„å»ºæ–‡æ¡£æ ‘"""
        time.sleep(0.3)  # æ ‘æ„å»ºæ¯”è¾ƒè€—æ—¶
        
        return {
            "tree_levels": self.tree_depth,
            "total_nodes": self.cluster_size * self.tree_depth,
            "question_context": question
        }
    
    def _hierarchical_retrieve(self, question: str, tree: Dict[str, Any]) -> List[str]:
        """æ¨¡æ‹Ÿå±‚æ¬¡åŒ–æ£€ç´¢"""
        time.sleep(0.15)
        
        retrieved_docs = []
        for level in range(self.tree_depth):
            level_docs = [
                f"RAPTOR Level-{level+1} doc {i+1} for: {question[:40]}..."
                for i in range(self.cluster_size // (level + 1))
            ]
            retrieved_docs.extend(level_docs)
        
        return retrieved_docs
    
    def _generate(self, question: str, contexts: List[str]) -> str:
        """æ¨¡æ‹Ÿç”Ÿæˆè¿‡ç¨‹"""
        time.sleep(0.25)
        return f"RAPTOR hierarchical answer for: {question[:30]}... (from {len(contexts)} level docs)"


# æ–¹æ³•æ³¨å†Œè¡¨
BASELINE_METHODS = {
    "naive_rag": NaiveRAG,
    "self_rag": SelfRAG,
    "raptor": RAPTOR,
}


def create_baseline_method(method_name: str, config: Dict[str, Any]) -> BaseRAGMethod:
    """
    åˆ›å»ºåŸºçº¿æ–¹æ³•å®ä¾‹
    
    Args:
        method_name: æ–¹æ³•åç§°
        config: é…ç½®å­—å…¸
        
    Returns:
        BaseRAGMethod: æ–¹æ³•å®ä¾‹
    """
    if method_name not in BASELINE_METHODS:
        raise ValueError(f"ä¸æ”¯æŒçš„åŸºçº¿æ–¹æ³•: {method_name}")
    
    method_class = BASELINE_METHODS[method_name]
    return method_class(config)


if __name__ == "__main__":
    # æµ‹è¯•åŸºçº¿æ–¹æ³•
    print("ğŸ§ª æµ‹è¯•åŸºçº¿æ–¹æ³•")
    
    config = {
        "retrieval_topk": 5,
        "max_tokens": 256,
        "max_iterations": 2,
        "tree_depth": 3
    }
    
    test_question = "What is the capital of France?"
    
    for method_name in BASELINE_METHODS.keys():
        print(f"\nğŸ“Š æµ‹è¯• {method_name}")
        method = create_baseline_method(method_name, config)
        result = method.process_query(test_question)
        
        print(f"ç­”æ¡ˆ: {result['answer']}")
        print(f"æ£€ç´¢æ—¶é—´: {result['retrieval_time']:.3f}s")
        print(f"ç”Ÿæˆæ—¶é—´: {result['generation_time']:.3f}s")
