#!/usr/bin/env python3
"""
=== æ™ºèƒ½è‡ªé€‚åº” RAG WebUI ç•Œé¢ ===

å€Ÿé‰´ FlashRAG çš„ Gradio ç•Œé¢è®¾è®¡å’Œ FlexRAG çš„äº¤äº’ä½“éªŒ
æä¾›ç›´è§‚çš„ RAG ç³»ç»Ÿé…ç½®å’Œæµ‹è¯•ç•Œé¢

è®¾è®¡ç†å¿µï¼š
1. å€Ÿé‰´ FlashRAG çš„æ¨¡å—åŒ–ç»„ä»¶è®¾è®¡
2. å‚è€ƒ FlexRAG çš„ç°ä»£åŒ– UI é£æ ¼
3. èåˆ LightRAG çš„å¯è§†åŒ–å±•ç¤º
4. åˆ›æ–°çš„è‡ªé€‚åº”é…ç½®ç•Œé¢
"""

import gradio as gr
import json
import time
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from adaptive_rag.config import create_flexrag_integrated_config, FLEXRAG_AVAILABLE
from adaptive_rag.core.flexrag_integrated_assistant import FlexRAGIntegratedAssistant
import yaml


class MockDataManager:
    """æ¨¡æ‹Ÿæ•°æ®ç®¡ç†å™¨ - ç”¨äºWebUIå±•ç¤º"""

    def __init__(self):
        self.corpus_stats = {
            "total_documents": 1000,
            "total_tokens": 500000,
            "avg_doc_length": 500,
            "last_updated": "2024-01-01 12:00:00"
        }

    def get_corpus_stats(self):
        """è·å–è¯­æ–™åº“ç»Ÿè®¡ä¿¡æ¯"""
        return self.corpus_stats

    def search_documents(self, query: str, top_k: int = 5):
        """æ¨¡æ‹Ÿæ–‡æ¡£æœç´¢"""
        return [
            {
                "id": f"doc_{i}",
                "title": f"Document {i}",
                "content": f"This is a sample document about {query}...",
                "score": 0.9 - i * 0.1
            }
            for i in range(1, min(top_k + 1, 6))
        ]


class RealConfigAdaptiveRAGEngine:
    """ä½¿ç”¨çœŸå®é…ç½®çš„ AdaptiveRAG å¼•æ“"""

    def __init__(self, config_path: str = "real_config.yaml"):
        """åˆå§‹åŒ–å¼•æ“"""
        self.config_path = config_path
        self.config = self.load_config()
        self.data_manager = MockDataManager()
        self.last_results = None

        # ä½¿ç”¨çœŸå®é…ç½®åˆå§‹åŒ– FlexRAG é›†æˆåŠ©æ‰‹
        try:
            # åˆ›å»º FlexRAG å…¼å®¹çš„é…ç½®
            flexrag_config = self.create_flexrag_config()
            self.assistant = FlexRAGIntegratedAssistant(flexrag_config)
            self.flexrag_available = True
        except Exception as e:
            print(f"âš ï¸ FlexRAG é›†æˆåŠ©æ‰‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.assistant = None
            self.flexrag_available = False

        print(f"âœ… çœŸå®é…ç½® AdaptiveRAG å¼•æ“åˆå§‹åŒ–å®Œæˆ")
        print(f"   é…ç½®æ–‡ä»¶: {self.config_path}")
        print(f"   FlexRAG å¯ç”¨: {'æ˜¯' if self.flexrag_available else 'å¦'}")

    def load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            print(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {self.config_path}")
            return config
        except Exception as e:
            print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            return self.get_default_config()

    def get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "device": "cuda",
            "retriever_configs": {},
            "generator_configs": {},
            "ranker_configs": {}
        }

    def get_config_summary(self) -> str:
        """è·å–é…ç½®æ‘˜è¦"""
        summary = []
        summary.append("ğŸ“‹ **å½“å‰é…ç½®æ‘˜è¦**\n")

        # åŸºç¡€è®¾ç½®
        summary.append(f"ğŸ–¥ï¸ **è®¾å¤‡**: {self.config.get('device', 'N/A')}")
        summary.append(f"ğŸ”¢ **æ‰¹æ¬¡å¤§å°**: {self.config.get('batch_size', 'N/A')}")
        summary.append(f"ğŸ¯ **æ•°æ®é›†**: {self.config.get('dataset_name', 'N/A')}")

        # æ£€ç´¢å™¨é…ç½®
        retrievers = self.config.get('retriever_configs', {})
        summary.append(f"\nğŸ” **æ£€ç´¢å™¨é…ç½®** ({len(retrievers)} ä¸ª):")
        for name, config in retrievers.items():
            retriever_type = config.get('retriever_type', 'unknown')
            status = "âœ… çœŸå®" if retriever_type != "mock" else "ğŸ”„ æ¨¡æ‹Ÿ"
            summary.append(f"   â€¢ {name}: {retriever_type} {status}")

        # ç”Ÿæˆå™¨é…ç½®
        generators = self.config.get('generator_configs', {})
        summary.append(f"\nğŸ¤– **ç”Ÿæˆå™¨é…ç½®** ({len(generators)} ä¸ª):")
        for name, config in generators.items():
            generator_type = config.get('generator_type', 'unknown')
            status = "âœ… çœŸå®" if generator_type != "mock" else "ğŸ”„ æ¨¡æ‹Ÿ"
            summary.append(f"   â€¢ {name}: {generator_type} {status}")

        # é‡æ’åºå™¨é…ç½®
        rankers = self.config.get('ranker_configs', {})
        summary.append(f"\nğŸ“Š **é‡æ’åºå™¨é…ç½®** ({len(rankers)} ä¸ª):")
        for name, config in rankers.items():
            ranker_type = config.get('ranker_type', 'unknown')
            status = "âœ… çœŸå®" if ranker_type != "mock" else "ğŸ”„ æ¨¡æ‹Ÿ"
            summary.append(f"   â€¢ {name}: {ranker_type} {status}")

        return "\n".join(summary)

    def create_flexrag_config(self):
        """åˆ›å»º FlexRAG å…¼å®¹çš„é…ç½®"""
        from adaptive_rag.config import FlexRAGIntegratedConfig

        # åˆ›å»ºåŸºç¡€é…ç½®
        flexrag_config = FlexRAGIntegratedConfig()

        # æ›´æ–°æ£€ç´¢å™¨é…ç½®
        if 'retriever_configs' in self.config:
            for name, config in self.config['retriever_configs'].items():
                if name in flexrag_config.retriever_configs:
                    # æ›´æ–°æ£€ç´¢å™¨ç±»å‹å’Œé…ç½®
                    flexrag_config.retriever_configs[name]['retriever_type'] = config.get('retriever_type', 'mock')
                    if 'config' not in flexrag_config.retriever_configs[name]:
                        flexrag_config.retriever_configs[name]['config'] = {}

                    # æ›´æ–°å…·ä½“é…ç½®
                    if 'model_path' in config:
                        flexrag_config.retriever_configs[name]['config']['model_path'] = config['model_path']
                    if 'model_name' in config:
                        flexrag_config.retriever_configs[name]['config']['model_name'] = config['model_name']
                    if 'index_path' in config:
                        flexrag_config.retriever_configs[name]['config']['index_path'] = config['index_path']
                    if 'corpus_path' in config:
                        flexrag_config.retriever_configs[name]['config']['corpus_path'] = config['corpus_path']

        # æ›´æ–°é‡æ’åºå™¨é…ç½®
        if 'ranker_configs' in self.config:
            for name, config in self.config['ranker_configs'].items():
                if name in flexrag_config.ranker_configs:
                    flexrag_config.ranker_configs[name]['ranker_type'] = config.get('ranker_type', 'mock')
                    if 'config' not in flexrag_config.ranker_configs[name]:
                        flexrag_config.ranker_configs[name]['config'] = {}

                    if 'model_path' in config:
                        flexrag_config.ranker_configs[name]['config']['model_path'] = config['model_path']
                    if 'model_name' in config:
                        flexrag_config.ranker_configs[name]['config']['model_name'] = config['model_name']

        # æ›´æ–°ç”Ÿæˆå™¨é…ç½®
        if 'generator_configs' in self.config:
            for name, config in self.config['generator_configs'].items():
                if name in flexrag_config.generator_configs:
                    flexrag_config.generator_configs[name]['generator_type'] = config.get('generator_type', 'mock')
                    if 'config' not in flexrag_config.generator_configs[name]:
                        flexrag_config.generator_configs[name]['config'] = {}

                    if 'model_path' in config:
                        flexrag_config.generator_configs[name]['config']['model_path'] = config['model_path']
                    if 'model_name' in config:
                        flexrag_config.generator_configs[name]['config']['model_name'] = config['model_name']

        # æ›´æ–°ç¼–ç å™¨é…ç½®
        if 'encoder_configs' in self.config:
            for name, config in self.config['encoder_configs'].items():
                if name in flexrag_config.encoder_configs:
                    flexrag_config.encoder_configs[name]['encoder_type'] = config.get('encoder_type', 'sentence_transformer')
                    if 'sentence_transformer_config' not in flexrag_config.encoder_configs[name]:
                        flexrag_config.encoder_configs[name]['sentence_transformer_config'] = {}

                    if 'model_path' in config:
                        flexrag_config.encoder_configs[name]['sentence_transformer_config']['model_name'] = config['model_path']
                    if 'model_name' in config:
                        flexrag_config.encoder_configs[name]['sentence_transformer_config']['model_name'] = config['model_name']

        # æ›´æ–°è®¾å¤‡é…ç½®
        flexrag_config.device = self.config.get('device', 'cuda')
        flexrag_config.batch_size = self.config.get('batch_size', 4)

        return flexrag_config

    def initialize_components(self):
        """åˆå§‹åŒ–ç»„ä»¶"""
        pass

    def process_query(self, query: str, show_details: bool = True) -> Dict[str, Any]:
        """å¤„ç†æŸ¥è¯¢ï¼ˆä½¿ç”¨çœŸå®é…ç½®çš„æ¨¡æ‹Ÿå®ç°ï¼‰"""
        start_time = time.time()

        print(f"ğŸ” å¤„ç†æŸ¥è¯¢: {query}")

        # æ¨¡æ‹Ÿå„ä¸ªé˜¶æ®µ
        stages = {
            "query_analysis": self.simulate_query_analysis(query),
            "strategy_planning": self.simulate_strategy_planning(query),
            "retrieval": self.simulate_retrieval(query),
            "reranking": self.simulate_reranking(query),
            "generation": self.simulate_generation(query)
        }

        total_time = time.time() - start_time

        result = {
            "query": query,
            "stages": stages,
            "total_time": total_time,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "answer": stages["generation"]["generated_answer"],
            "retrieved_docs": stages["retrieval"]["retriever_results"],
            "processing_details": {
                "query_analysis_time": stages["query_analysis"]["processing_time"],
                "strategy_planning_time": stages["strategy_planning"]["processing_time"],
                "retrieval_time": stages["retrieval"]["processing_time"],
                "reranking_time": stages["reranking"]["processing_time"],
                "generation_time": stages["generation"]["processing_time"]
            }
        }

        self.last_results = result
        return result

    def simulate_query_analysis(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹ŸæŸ¥è¯¢åˆ†æé˜¶æ®µ"""
        time.sleep(0.1)

        words = query.lower().split()
        complexity_score = min(len(words) / 10.0, 1.0)

        question_words = ['what', 'who', 'where', 'when', 'why', 'how']
        has_question_word = any(word in words for word in question_words)

        multi_hop_indicators = ['and', 'also', 'furthermore', 'additionally']
        is_multi_hop = any(indicator in words for indicator in multi_hop_indicators)

        return {
            "complexity_score": complexity_score,
            "word_count": len(words),
            "has_question_word": has_question_word,
            "is_multi_hop": is_multi_hop,
            "query_type": "multi_hop" if is_multi_hop else "single_hop",
            "processing_time": 0.1
        }

    def simulate_strategy_planning(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿç­–ç•¥è§„åˆ’é˜¶æ®µ"""
        time.sleep(0.1)

        analysis = self.simulate_query_analysis(query)

        if analysis["is_multi_hop"]:
            weights = {"keyword": 0.3, "dense": 0.5, "web": 0.2}
            strategy = "multi_hop_strategy"
        else:
            weights = {"keyword": 0.6, "dense": 0.3, "web": 0.1}
            strategy = "single_hop_strategy"

        return {
            "selected_strategy": strategy,
            "retriever_weights": weights,
            "confidence": 0.85,
            "reasoning": f"åŸºäºæŸ¥è¯¢å¤æ‚åº¦ {analysis['complexity_score']:.2f} é€‰æ‹©ç­–ç•¥",
            "processing_time": 0.1
        }

    def simulate_retrieval(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæ£€ç´¢é˜¶æ®µ"""
        time.sleep(0.2)

        retrievers = self.config.get('retriever_configs', {})
        results = {}

        for retriever_name, config in retrievers.items():
            retriever_type = config.get('retriever_type', 'mock')
            top_k = config.get('top_k', 5)

            docs = []
            for i in range(top_k):
                docs.append({
                    "id": f"{retriever_name}_doc_{i}",
                    "title": f"Document {i} from {retriever_name}",
                    "content": f"Content from {retriever_name} for: {query[:50]}...",
                    "score": 0.9 - i * 0.1,
                    "source": retriever_name
                })

            results[retriever_name] = {
                "type": retriever_type,
                "documents": docs,
                "total_found": top_k,
                "processing_time": 0.05
            }

        return {
            "retriever_results": results,
            "total_documents": sum(len(r["documents"]) for r in results.values()),
            "processing_time": 0.2
        }

    def simulate_reranking(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿé‡æ’åºé˜¶æ®µ"""
        time.sleep(0.1)

        rankers = self.config.get('ranker_configs', {})

        reranked_docs = []
        for i in range(5):
            reranked_docs.append({
                "id": f"reranked_doc_{i}",
                "title": f"Reranked Document {i}",
                "content": f"Reranked content for: {query[:50]}...",
                "original_score": 0.8 - i * 0.1,
                "rerank_score": 0.95 - i * 0.05,
                "rank_change": i % 3 - 1
            })

        return {
            "ranker_used": list(rankers.keys())[0] if rankers else "default",
            "reranked_documents": reranked_docs,
            "score_improvement": 0.15,
            "processing_time": 0.1
        }

    def simulate_generation(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿç”Ÿæˆé˜¶æ®µ"""
        time.sleep(0.3)

        generators = self.config.get('generator_configs', {})
        main_generator = list(generators.keys())[0] if generators else "default"

        answer = f"Based on the retrieved information, here's the answer to '{query}': This is a simulated response generated using the {main_generator} generator with real configuration settings."

        return {
            "generator_used": main_generator,
            "generated_answer": answer,
            "confidence": 0.88,
            "token_count": len(answer.split()),
            "processing_time": 0.3
        }


class AdaptiveRAGEngine:
    """æ™ºèƒ½è‡ªé€‚åº” RAG å¼•æ“ - å€Ÿé‰´ FlashRAG çš„ Engine è®¾è®¡"""
    
    def __init__(self):
        self.config = create_flexrag_integrated_config()

        # åˆå§‹åŒ– FlexRAG é›†æˆåŠ©æ‰‹
        self.assistant = FlexRAGIntegratedAssistant(self.config)

        # è·å–ç³»ç»Ÿä¿¡æ¯
        self.system_info = self.assistant.get_system_info()

        # çŠ¶æ€ç®¡ç†
        self.is_initialized = True
        self.current_query = ""
        self.last_results = None

        # æ·»åŠ æ•°æ®ç®¡ç†å™¨ï¼ˆæ¨¡æ‹Ÿï¼‰
        self.data_manager = MockDataManager()

        print(f"âœ… AdaptiveRAG å¼•æ“åˆå§‹åŒ–å®Œæˆ")
        print(f"   FlexRAG å¯ç”¨: {'æ˜¯' if FLEXRAG_AVAILABLE else 'å¦'}")
        print(f"   åŠ©æ‰‹ç±»å‹: {self.system_info['assistant_type']}")
        print(f"   æ”¯æŒåŠŸèƒ½: {', '.join(self.system_info['supported_features'])}")
        
    def initialize_components(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶ï¼ˆFlexRAG é›†æˆç‰ˆæœ¬ä¸­å·²è‡ªåŠ¨å®Œæˆï¼‰"""
        # FlexRAG é›†æˆåŠ©æ‰‹å·²ç»åœ¨ __init__ ä¸­å®Œæˆäº†æ‰€æœ‰åˆå§‹åŒ–
        pass
    
    def process_query(self, query: str, show_details: bool = True) -> Dict[str, Any]:
        """å¤„ç†æŸ¥è¯¢ - ä½¿ç”¨ FlexRAG é›†æˆåŠ©æ‰‹"""
        start_time = time.time()

        # ä½¿ç”¨ FlexRAG é›†æˆåŠ©æ‰‹å¤„ç†æŸ¥è¯¢
        result = self.assistant.answer(query)

        processing_time = time.time() - start_time

        # è½¬æ¢ä¸º Web UI å…¼å®¹çš„æ ¼å¼
        web_result = {
            "query": query,
            "answer": result.answer,
            "subtasks": result.subtasks,
            "retrieval_results": result.retrieval_results,
            "ranking_results": result.ranking_results,
            "generation_result": result.generation_result,
            "processing_time": processing_time,
            "total_time": result.total_time,
            "metadata": result.metadata
        }

        self.current_query = query
        self.last_results = web_result

        return web_result


def create_basic_tab(engine: AdaptiveRAGEngine) -> Dict[str, gr.Component]:
    """åˆ›å»ºåŸºç¡€é…ç½®æ ‡ç­¾é¡µ - å€Ÿé‰´ FlashRAG çš„è®¾è®¡"""
    
    with gr.Tab("ğŸ”§ åŸºç¡€é…ç½®") as basic_tab:
        gr.HTML("<h3>ç³»ç»Ÿé…ç½®</h3>")
        
        with gr.Row():
            with gr.Column(scale=1):
                # æ¨¡å‹é…ç½®
                gr.HTML("<h4>ğŸ“¦ æ¨¡å‹é…ç½®</h4>")
                
                dense_model_path = gr.Textbox(
                    label="å‘é‡æ£€ç´¢æ¨¡å‹è·¯å¾„",
                    value="./adaptive_rag/models/e5-base-v2",
                    placeholder="/path/to/dense/model"
                )

                generator_model_path = gr.Textbox(
                    label="ç”Ÿæˆæ¨¡å‹è·¯å¾„",
                    value="./adaptive_rag/models/qwen1.5-1.8b",
                    placeholder="/path/to/generator/model"
                )

                reranker_model_path = gr.Textbox(
                    label="é‡æ’åºæ¨¡å‹è·¯å¾„",
                    value="./adaptive_rag/models/bge-reranker-base",
                    placeholder="/path/to/reranker/model"
                )
            
            with gr.Column(scale=1):
                # æ•°æ®é…ç½®
                gr.HTML("<h4>ğŸ“Š æ•°æ®é…ç½®</h4>")
                
                corpus_path = gr.Textbox(
                    label="è¯­æ–™åº“è·¯å¾„",
                    value="./adaptive_rag/data/general_knowledge.jsonl",
                    placeholder="/path/to/corpus.jsonl"
                )

                index_path = gr.Textbox(
                    label="ç´¢å¼•è·¯å¾„",
                    value="./adaptive_rag/data/e5_Flat.index",
                    placeholder="/path/to/index"
                )

                batch_size = gr.Slider(
                    minimum=1,
                    maximum=32,
                    value=engine.config.batch_size,
                    step=1,
                    label="æ‰¹å¤„ç†å¤§å°"
                )
        
        with gr.Row():
            save_config_btn = gr.Button("ğŸ’¾ ä¿å­˜é…ç½®", variant="primary")
            load_config_btn = gr.Button("ğŸ“‚ åŠ è½½é…ç½®")
            reset_config_btn = gr.Button("ğŸ”„ é‡ç½®é…ç½®")
        
        config_status = gr.Textbox(
            label="é…ç½®çŠ¶æ€",
            value="é…ç½®æœªä¿å­˜",
            interactive=False
        )
    
    return {
        "basic_tab": basic_tab,
        "dense_model_path": dense_model_path,
        "generator_model_path": generator_model_path,
        "reranker_model_path": reranker_model_path,
        "corpus_path": corpus_path,
        "index_path": index_path,
        "batch_size": batch_size,
        "save_config_btn": save_config_btn,
        "load_config_btn": load_config_btn,
        "reset_config_btn": reset_config_btn,
        "config_status": config_status
    }


def create_query_tab(engine: AdaptiveRAGEngine) -> Dict[str, gr.Component]:
    """åˆ›å»ºæŸ¥è¯¢æµ‹è¯•æ ‡ç­¾é¡µ"""
    
    with gr.Tab("ğŸ” æ™ºèƒ½æ£€ç´¢") as query_tab:
        gr.HTML("<h3>æ™ºèƒ½è‡ªé€‚åº”æ£€ç´¢æµ‹è¯•</h3>")
        
        with gr.Row():
            with gr.Column(scale=2):
                query_input = gr.Textbox(
                    label="è¾“å…¥æŸ¥è¯¢",
                    placeholder="ä¾‹å¦‚: What is artificial intelligence?",
                    lines=3
                )
                
                with gr.Row():
                    search_btn = gr.Button("ğŸš€ æ™ºèƒ½æ£€ç´¢", variant="primary", size="lg")
                    clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º", size="lg")
                
                # æ£€ç´¢é…ç½®
                with gr.Accordion("âš™ï¸ æ£€ç´¢é…ç½®", open=False):
                    show_details = gr.Checkbox(
                        label="æ˜¾ç¤ºè¯¦ç»†è¿‡ç¨‹",
                        value=True
                    )
                    
                    max_results = gr.Slider(
                        minimum=1,
                        maximum=20,
                        value=10,
                        step=1,
                        label="æœ€å¤§ç»“æœæ•°"
                    )
            
            with gr.Column(scale=1):
                # ç³»ç»ŸçŠ¶æ€
                gr.HTML("<h4>ğŸ“Š ç³»ç»ŸçŠ¶æ€</h4>")
                
                system_status = gr.HTML(
                    value="<p><span style='color: orange;'>â—</span> ç³»ç»Ÿæœªåˆå§‹åŒ–</p>"
                )
                
                corpus_info = gr.HTML(
                    value="<p><strong>è¯­æ–™åº“:</strong> æœªåŠ è½½</p>"
                )
                
                # ç¤ºä¾‹æŸ¥è¯¢
                gr.HTML("<h4>ğŸ’¡ ç¤ºä¾‹æŸ¥è¯¢</h4>")
                
                example_queries = [
                    "What is artificial intelligence?",
                    "Compare machine learning and deep learning",
                    "When was the iPhone first released?",
                    "Why did the Roman Empire fall?"
                ]
                
                for query in example_queries:
                    example_btn = gr.Button(
                        f"ğŸ“ {query[:30]}...",
                        size="sm",
                        variant="secondary"
                    )
        
        # ç»“æœæ˜¾ç¤ºåŒºåŸŸ
        with gr.Row():
            with gr.Column():
                # ä»»åŠ¡åˆ†è§£ç»“æœ
                task_decomposition = gr.JSON(
                    label="ğŸ§  ä»»åŠ¡åˆ†è§£ç»“æœ",
                    visible=False
                )
                
                # æ£€ç´¢ç­–ç•¥
                retrieval_strategy = gr.JSON(
                    label="ğŸ¯ æ£€ç´¢ç­–ç•¥è§„åˆ’",
                    visible=False
                )
                
                # æ£€ç´¢ç»“æœ
                search_results = gr.Textbox(
                    label="ğŸ” æ£€ç´¢ç»“æœ",
                    lines=15,
                    max_lines=20,
                    show_copy_button=True
                )
        
        # æ€§èƒ½ç»Ÿè®¡
        with gr.Row():
            processing_time = gr.Textbox(
                label="â±ï¸ å¤„ç†æ—¶é—´",
                interactive=False,
                scale=1
            )
            
            total_results = gr.Textbox(
                label="ğŸ“Š ç»“æœç»Ÿè®¡",
                interactive=False,
                scale=1
            )
    
    return {
        "query_tab": query_tab,
        "query_input": query_input,
        "search_btn": search_btn,
        "clear_btn": clear_btn,
        "show_details": show_details,
        "max_results": max_results,
        "system_status": system_status,
        "corpus_info": corpus_info,
        "task_decomposition": task_decomposition,
        "retrieval_strategy": retrieval_strategy,
        "search_results": search_results,
        "processing_time": processing_time,
        "total_results": total_results
    }


def create_analysis_tab(engine: AdaptiveRAGEngine) -> Dict[str, gr.Component]:
    """åˆ›å»ºåˆ†æå¯è§†åŒ–æ ‡ç­¾é¡µ"""
    
    with gr.Tab("ğŸ“ˆ ç»“æœåˆ†æ") as analysis_tab:
        gr.HTML("<h3>æ£€ç´¢ç»“æœåˆ†æä¸å¯è§†åŒ–</h3>")
        
        with gr.Row():
            with gr.Column():
                # ä»»åŠ¡åˆ†è§£å¯è§†åŒ–
                gr.HTML("<h4>ğŸ§  ä»»åŠ¡åˆ†è§£åˆ†æ</h4>")
                task_analysis = gr.Plot(label="ä»»åŠ¡ç±»å‹åˆ†å¸ƒ")
                
                # æ£€ç´¢å™¨ä½¿ç”¨ç»Ÿè®¡
                gr.HTML("<h4>ğŸ” æ£€ç´¢å™¨ä½¿ç”¨ç»Ÿè®¡</h4>")
                retriever_stats = gr.Plot(label="æ£€ç´¢å™¨æ•ˆæœå¯¹æ¯”")
            
            with gr.Column():
                # ç›¸å…³åº¦åˆ†å¸ƒ
                gr.HTML("<h4>ğŸ“Š ç›¸å…³åº¦åˆ†å¸ƒ</h4>")
                relevance_dist = gr.Plot(label="ç»“æœç›¸å…³åº¦åˆ†å¸ƒ")
                
                # å¤„ç†æ—¶é—´åˆ†æ
                gr.HTML("<h4>â±ï¸ æ€§èƒ½åˆ†æ</h4>")
                performance_stats = gr.HTML(
                    value="<p>æš‚æ— æ€§èƒ½æ•°æ®</p>"
                )
        
        # è¯¦ç»†ç»“æœè¡¨æ ¼
        with gr.Row():
            results_table = gr.Dataframe(
                headers=["æ’å", "å†…å®¹", "åˆ†æ•°", "æ£€ç´¢å™¨", "å…ƒæ•°æ®"],
                label="ğŸ“‹ è¯¦ç»†ç»“æœè¡¨æ ¼",
                interactive=False
            )
    
    return {
        "analysis_tab": analysis_tab,
        "task_analysis": task_analysis,
        "retriever_stats": retriever_stats,
        "relevance_dist": relevance_dist,
        "performance_stats": performance_stats,
        "results_table": results_table
    }


def create_ui_with_real_config(config_path: str = "real_config.yaml") -> gr.Blocks:
    """åˆ›å»ºä½¿ç”¨çœŸå®é…ç½®çš„ä¸»ç•Œé¢"""

    # åˆå§‹åŒ–çœŸå®é…ç½®å¼•æ“
    engine = RealConfigAdaptiveRAGEngine(config_path)

    # è‡ªå®šä¹‰ CSSï¼ˆä¿æŒåŸæœ‰é£æ ¼ï¼‰
    custom_css = """
    /* Gradio å®¹å™¨å’Œä¸»å†…å®¹åŒºåŸŸåº”å æ®å…¨å®½ï¼Œç§»é™¤æœ€å¤§å®½åº¦é™åˆ¶å’Œè‡ªåŠ¨è¾¹è· */
    .gradio-container, .main, .container {
        max-width: none !important; /* ç§»é™¤æœ€å¤§å®½åº¦é™åˆ¶ */
        margin: 0 !important; /* ç§»é™¤è‡ªåŠ¨è¾¹è· */
        padding: 0 !important; /* ç§»é™¤å†…è¾¹è·ï¼Œç¡®ä¿å†…å®¹è´´è¾¹ */
    }

    .tab-nav {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        border-radius: 8px 8px 0 0;
    }

    /* æŒ‰é’®æ ·å¼ä¼˜åŒ– */
    .primary-button {
        background: linear-gradient(45deg, #667eea, #764ba2);
        border: none;
        color: white;
        border-radius: 6px;
        transition: all 0.3s ease;
    }

    .primary-button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
    }

    /* ç¡®ä¿æ•´ä¸ªé¡µé¢æ— ç•™ç™½ */
    body {
        margin: 0 !important; /* ç§»é™¤è‡ªåŠ¨è¾¹è· */
        max-width: none !important; /* ç§»é™¤æœ€å¤§å®½åº¦é™åˆ¶ */
        padding: 0 !important; /* ç§»é™¤å†…è¾¹è· */
    }

    /* æ ‡é¢˜åŒºåŸŸå±…ä¸­ */
    .title-container {
        text-align: center;
        margin: 0; /* è°ƒæ•´ä¸º0ï¼Œè®©å®ƒè‡ªå·±æ§åˆ¶å®½åº¦ */
        padding: 30px 20px; /* å¢åŠ ä¸Šä¸‹å†…è¾¹è·ï¼Œå·¦å³ä¿æŒä¸€è‡´ */
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 12px;
        box-shadow: 0 4px 20px rgba(102, 126, 234, 0.3);
        width: 100%; /* ç¡®ä¿æ ‡é¢˜å®¹å™¨ä¹Ÿå æ®å…¨å®½ */
        box-sizing: border-box; /* ç¡®ä¿ padding ä¸ä¼šå¢åŠ æ€»å®½åº¦ */
    }

    /* æ ‡ç­¾é¡µæ ·å¼ä¼˜åŒ– */
    .tab-item {
        border-radius: 8px;
        margin: 2px;
        flex-grow: 1; /* è®©æ ‡ç­¾é¡µé¡¹ç›®ç­‰å®½åˆ†å¸ƒ */
    }

    /* è¾“å…¥æ¡†å’ŒæŒ‰é’®æ ·å¼ä¼˜åŒ– */
    .gr-textbox, .gr-slider {
        border-radius: 6px;
        border: 1px solid #e1e5e9;
    }

    .gr-button {
        border-radius: 6px;
        transition: all 0.3s ease;
    }

    /* å“åº”å¼è®¾è®¡ */
    @media (max-width: 768px) {
        .gradio-container, .main, .container {
            max-width: 100% !important;
            padding: 10px !important;
        }

        .title-container {
            margin: 0; /* è°ƒæ•´ä¸º0 */
            padding: 15px;
        }
    }
    """

    with gr.Blocks(
        title="ğŸ§  æ™ºèƒ½è‡ªé€‚åº” RAG ç³»ç»Ÿ - çœŸå®é…ç½®",
        theme=gr.themes.Soft(
            primary_hue="blue",
            secondary_hue="purple",
            neutral_hue="slate",
            spacing_size="md",
            radius_size="md"
        ),
        css=custom_css,
        head="""
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <style>
            body {
                margin: 0 auto !important;
                max-width: 1200px !important;
                background-color: #f8fafc;
            }
        </style>
        """
    ) as demo:

        # æ ‡é¢˜å’Œä»‹ç»
        gr.HTML("""
        <div class="title-container">
            <h1 style="margin: 0 0 10px 0; font-size: 2.5em; font-weight: 700;">
                ğŸ§  æ™ºèƒ½è‡ªé€‚åº” RAG ç³»ç»Ÿ
            </h1>
            <h3 style="margin: 0 0 15px 0; font-size: 1.3em; font-weight: 400; opacity: 0.9;">
                åŸºäºçœŸå®é…ç½®çš„å¢å¼ºæ£€ç´¢ç”Ÿæˆç³»ç»Ÿ
            </h3>
            <p style="margin: 0; font-size: 1em; opacity: 0.8; line-height: 1.6;">
                ä½¿ç”¨çœŸå®çš„æ£€ç´¢å™¨ã€ç”Ÿæˆå™¨å’Œé‡æ’åºå™¨ï¼Œå±•ç¤ºå®Œæ•´çš„ AdaptiveRAG æµç¨‹
            </p>
        </div>
        """)

        # åˆ›å»ºæ ‡ç­¾é¡µ
        with gr.Tabs():
            # é…ç½®ä¿¡æ¯æ ‡ç­¾é¡µ
            with gr.Tab("âš™ï¸ é…ç½®ä¿¡æ¯"):
                gr.HTML("<h2>ğŸ“‹ ç³»ç»Ÿé…ç½®ä¿¡æ¯</h2>")

                config_display = gr.Markdown(
                    value=engine.get_config_summary(),
                    label="é…ç½®æ‘˜è¦"
                )

                with gr.Row():
                    refresh_config_btn = gr.Button("ğŸ”„ åˆ·æ–°é…ç½®", variant="secondary")
                    reload_config_btn = gr.Button("ğŸ“ é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶", variant="primary")

                config_status = gr.Textbox(
                    label="çŠ¶æ€",
                    value="é…ç½®å·²åŠ è½½",
                    interactive=False
                )

                def refresh_config():
                    return engine.get_config_summary(), "é…ç½®å·²åˆ·æ–°"

                def reload_config():
                    engine.config = engine.load_config()
                    return engine.get_config_summary(), "é…ç½®æ–‡ä»¶å·²é‡æ–°åŠ è½½"

                refresh_config_btn.click(
                    refresh_config,
                    outputs=[config_display, config_status]
                )

                reload_config_btn.click(
                    reload_config,
                    outputs=[config_display, config_status]
                )

            # æ™ºèƒ½æ£€ç´¢æ ‡ç­¾é¡µ
            with gr.Tab("ğŸ” æ™ºèƒ½æ£€ç´¢"):
                gr.HTML("<h2>ğŸ§  æ™ºèƒ½æŸ¥è¯¢å¤„ç†</h2>")

                with gr.Row():
                    with gr.Column(scale=2):
                        query_input = gr.Textbox(
                            label="è¾“å…¥æŸ¥è¯¢",
                            placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
                            lines=3
                        )

                        with gr.Row():
                            process_btn = gr.Button("ğŸš€ å¤„ç†æŸ¥è¯¢", variant="primary")
                            clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©º", variant="secondary")

                        show_details = gr.Checkbox(
                            label="æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯",
                            value=True
                        )

                    with gr.Column(scale=1):
                        gr.HTML("<h4>ğŸ“Š å¿«é€Ÿç»Ÿè®¡</h4>")
                        query_stats = gr.JSON(
                            label="æŸ¥è¯¢ç»Ÿè®¡",
                            value={"æ€»æŸ¥è¯¢æ•°": 0, "å¹³å‡å¤„ç†æ—¶é—´": "0.0s"}
                        )

                # ç»“æœå±•ç¤ºåŒºåŸŸ
                with gr.Row():
                    with gr.Column():
                        gr.HTML("<h3>ğŸ“ˆ å¤„ç†æµç¨‹</h3>")
                        process_flow = gr.JSON(label="å¤„ç†é˜¶æ®µè¯¦æƒ…")

                    with gr.Column():
                        gr.HTML("<h3>ğŸ’¬ ç”Ÿæˆç»“æœ</h3>")
                        generated_answer = gr.Textbox(
                            label="ç”Ÿæˆçš„ç­”æ¡ˆ",
                            lines=5,
                            interactive=False
                        )

                # æ£€ç´¢ç»“æœå±•ç¤º
                with gr.Row():
                    gr.HTML("<h3>ğŸ“š æ£€ç´¢ç»“æœ</h3>")

                retrieved_docs = gr.JSON(label="æ£€ç´¢åˆ°çš„æ–‡æ¡£")

                def process_query(query, show_details_flag):
                    if not query.strip():
                        return {}, "è¯·è¾“å…¥æœ‰æ•ˆçš„æŸ¥è¯¢", {}

                    result = engine.process_query(query, show_details_flag)

                    # æå–å¤„ç†æµç¨‹ä¿¡æ¯
                    flow_info = {}
                    for stage_name, stage_data in result["stages"].items():
                        flow_info[stage_name] = {
                            "å¤„ç†æ—¶é—´": f"{stage_data.get('processing_time', 0):.3f}s",
                            "çŠ¶æ€": "âœ… å®Œæˆ"
                        }

                    flow_info["æ€»å¤„ç†æ—¶é—´"] = f"{result['total_time']:.3f}s"

                    # æå–ç”Ÿæˆçš„ç­”æ¡ˆ
                    answer = result["stages"]["generation"]["generated_answer"]

                    # æå–æ£€ç´¢ç»“æœ
                    docs = result["stages"]["retrieval"]["retriever_results"]

                    return flow_info, answer, docs

                def clear_inputs():
                    return "", {}, "", {}

                process_btn.click(
                    process_query,
                    inputs=[query_input, show_details],
                    outputs=[process_flow, generated_answer, retrieved_docs]
                )

                clear_btn.click(
                    clear_inputs,
                    outputs=[query_input, process_flow, generated_answer, retrieved_docs]
                )

            # ç»“æœåˆ†ææ ‡ç­¾é¡µ
            with gr.Tab("ğŸ“ˆ ç»“æœåˆ†æ"):
                gr.HTML("<h2>ğŸ“Š æ€§èƒ½åˆ†æä¸å¯è§†åŒ–</h2>")

                with gr.Row():
                    with gr.Column():
                        gr.HTML("<h3>â±ï¸ æ€§èƒ½æŒ‡æ ‡</h3>")
                        performance_stats = gr.JSON(
                            label="æ€§èƒ½ç»Ÿè®¡",
                            value={
                                "å¹³å‡æŸ¥è¯¢åˆ†ææ—¶é—´": "0.1s",
                                "å¹³å‡æ£€ç´¢æ—¶é—´": "0.2s",
                                "å¹³å‡ç”Ÿæˆæ—¶é—´": "0.3s",
                                "æ€»å¹³å‡æ—¶é—´": "0.7s"
                            }
                        )

                    with gr.Column():
                        gr.HTML("<h3>ğŸ¯ å‡†ç¡®æ€§æŒ‡æ ‡</h3>")
                        accuracy_stats = gr.JSON(
                            label="å‡†ç¡®æ€§ç»Ÿè®¡",
                            value={
                                "æ£€ç´¢å‡†ç¡®ç‡": "85%",
                                "ç”Ÿæˆè´¨é‡": "88%",
                                "ç”¨æˆ·æ»¡æ„åº¦": "90%"
                            }
                        )

                with gr.Row():
                    gr.HTML("<h3>ğŸ“‹ æœ€è¿‘æŸ¥è¯¢å†å²</h3>")

                query_history = gr.Dataframe(
                    headers=["æ—¶é—´", "æŸ¥è¯¢", "å¤„ç†æ—¶é—´", "çŠ¶æ€"],
                    datatype=["str", "str", "str", "str"],
                    label="æŸ¥è¯¢å†å²"
                )

    return demo

def create_ui() -> gr.Blocks:
    """åˆ›å»ºä¸»ç•Œé¢ - å€Ÿé‰´ FlashRAG çš„æ•´ä½“è®¾è®¡"""

    # åˆå§‹åŒ–å¼•æ“
    engine = AdaptiveRAGEngine()
    
    # è‡ªå®šä¹‰ CSS
    custom_css = """
    /* Gradio å®¹å™¨å’Œä¸»å†…å®¹åŒºåŸŸåº”å æ®å…¨å®½ï¼Œç§»é™¤æœ€å¤§å®½åº¦é™åˆ¶å’Œè‡ªåŠ¨è¾¹è· */
    .gradio-container, .main, .container {
        max-width: none !important; /* ç§»é™¤æœ€å¤§å®½åº¦é™åˆ¶ */
        margin: 0 !important; /* ç§»é™¤è‡ªåŠ¨è¾¹è· */
        padding: 0 !important; /* ç§»é™¤å†…è¾¹è·ï¼Œç¡®ä¿å†…å®¹è´´è¾¹ */
    }

    .tab-nav {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        border-radius: 8px 8px 0 0;
    }

    /* æŒ‰é’®æ ·å¼ä¼˜åŒ– */
    .primary-button {
        background: linear-gradient(45deg, #667eea, #764ba2);
        border: none;
        color: white;
        border-radius: 6px;
        transition: all 0.3s ease;
    }

    .primary-button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
    }

    /* ç¡®ä¿æ•´ä¸ªé¡µé¢æ— ç•™ç™½ */
    body {
        margin: 0 !important; /* ç§»é™¤è‡ªåŠ¨è¾¹è· */
        max-width: none !important; /* ç§»é™¤æœ€å¤§å®½åº¦é™åˆ¶ */
        padding: 0 !important; /* ç§»é™¤å†…è¾¹è· */
    }

    /* æ ‡é¢˜åŒºåŸŸå±…ä¸­ */
    .title-container {
        text-align: center;
        margin: 0; /* è°ƒæ•´ä¸º0ï¼Œè®©å®ƒè‡ªå·±æ§åˆ¶å®½åº¦ */
        padding: 30px 20px; /* å¢åŠ ä¸Šä¸‹å†…è¾¹è·ï¼Œå·¦å³ä¿æŒä¸€è‡´ */
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 12px;
        box-shadow: 0 4px 20px rgba(102, 126, 234, 0.3);
        width: 100%; /* ç¡®ä¿æ ‡é¢˜å®¹å™¨ä¹Ÿå æ®å…¨å®½ */
        box-sizing: border-box; /* ç¡®ä¿ padding ä¸ä¼šå¢åŠ æ€»å®½åº¦ */
    }

    /* æ ‡ç­¾é¡µæ ·å¼ä¼˜åŒ– */
    .tab-item {
        border-radius: 8px;
        margin: 2px;
        flex-grow: 1; /* è®©æ ‡ç­¾é¡µé¡¹ç›®ç­‰å®½åˆ†å¸ƒ */
    }

    /* è¾“å…¥æ¡†å’ŒæŒ‰é’®æ ·å¼ä¼˜åŒ– */
    .gr-textbox, .gr-slider {
        border-radius: 6px;
        border: 1px solid #e1e5e9;
    }

    .gr-button {
        border-radius: 6px;
        transition: all 0.3s ease;
    }

    /* å“åº”å¼è®¾è®¡ */
    @media (max-width: 768px) {
        .gradio-container, .main, .container {
            max-width: 100% !important;
            padding: 10px !important;
        }

        .title-container {
            margin: 0; /* è°ƒæ•´ä¸º0 */
            padding: 15px;
        }
    }
    """
    
    with gr.Blocks(
        title="ğŸ§  æ™ºèƒ½è‡ªé€‚åº” RAG ç³»ç»Ÿ",
        theme=gr.themes.Soft(
            primary_hue="blue",
            secondary_hue="purple",
            neutral_hue="slate",
            spacing_size="md",
            radius_size="md"
        ),
        css=custom_css,
        head="""
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <style>
            body {
                margin: 0 auto !important;
                max-width: 1200px !important;
                background-color: #f8fafc;
            }
        </style>
        """
    ) as demo:
        
        # æ ‡é¢˜å’Œä»‹ç»
        gr.HTML("""
        <div class="title-container">
            <h1 style="margin: 0 0 10px 0; font-size: 2.5em; font-weight: 700;">
                ğŸ§  æ™ºèƒ½è‡ªé€‚åº” RAG ç³»ç»Ÿ
            </h1>
            <h3 style="margin: 0 0 15px 0; font-size: 1.3em; font-weight: 400; opacity: 0.9;">
                åŸºäºä»»åŠ¡åˆ†è§£å’ŒåŠ¨æ€æ£€ç´¢ç­–ç•¥çš„å¢å¼ºæ£€ç´¢ç”Ÿæˆç³»ç»Ÿ
            </h3>
            <p style="margin: 0; font-size: 1em; opacity: 0.8; line-height: 1.6;">
                å€Ÿé‰´ FlashRAGã€FlexRAGã€LevelRAG ç­‰ä¼˜ç§€æ¡†æ¶ï¼Œèåˆåˆ›æ–°çš„è‡ªé€‚åº”æ£€ç´¢æŠ€æœ¯
            </p>
        </div>
        """)
        
        # åˆ›å»ºå„ä¸ªæ ‡ç­¾é¡µ
        basic_components = create_basic_tab(engine)
        query_components = create_query_tab(engine)
        analysis_components = create_analysis_tab(engine)
        
        # äº‹ä»¶å¤„ç†å‡½æ•°
        def process_search(query, show_details, max_results):
            """å¤„ç†æœç´¢è¯·æ±‚"""
            if not query.strip():
                return (
                    "è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹",
                    gr.update(visible=False),
                    gr.update(visible=False),
                    "",
                    ""
                )

            try:
                # åˆå§‹åŒ–å¼•æ“
                engine.initialize_components()

                result = engine.process_query(query, show_details)

                # æ ¼å¼åŒ–ç»“æœ
                search_output = f"æŸ¥è¯¢: {result['query']}\n"
                search_output += f"å¤„ç†æ—¶é—´: {result['processing_time']:.2f}ç§’\n"

                # è®¡ç®—æ€»ç»“æœæ•°
                total_docs = 0
                if 'retrieval_results' in result:
                    total_docs = sum(len(r.contexts) for r in result['retrieval_results'])

                search_output += f"æ€»ç»“æœæ•°: {total_docs}\n"
                search_output += f"ç­”æ¡ˆ: {result.get('answer', 'æœªç”Ÿæˆç­”æ¡ˆ')}\n\n"

                search_output += "=== æ£€ç´¢ç»“æœè¯¦æƒ… ===\n"

                # æ˜¾ç¤ºæ£€ç´¢ç»“æœ
                if 'retrieval_results' in result:
                    for i, retrieval_result in enumerate(result['retrieval_results'], 1):
                        search_output += f"\n--- å­ä»»åŠ¡ {i}: {retrieval_result.query} ---\n"
                        for j, doc in enumerate(retrieval_result.contexts[:max_results], 1):
                            search_output += f"{j}. åˆ†æ•°: {doc.score:.3f}\n"
                            search_output += f"   å†…å®¹: {doc.content[:200]}...\n"
                            if hasattr(doc, 'metadata') and doc.metadata:
                                search_output += f"   å…ƒæ•°æ®: {doc.metadata}\n"

                # ä»»åŠ¡åˆ†è§£ä¿¡æ¯
                task_info = {
                    "subtasks": []
                }

                if 'subtasks' in result and result['subtasks']:
                    task_info["subtasks"] = [
                        {
                            "id": getattr(st, 'id', f"task_{i}"),
                            "content": getattr(st, 'content', str(st)),
                            "type": getattr(st, 'task_type', 'unknown').value if hasattr(getattr(st, 'task_type', None), 'value') else str(getattr(st, 'task_type', 'unknown')),
                            "priority": getattr(st, 'priority', 1.0),
                            "entities": getattr(st, 'entities', []),
                            "temporal_info": getattr(st, 'temporal_info', {})
                        }
                        for i, st in enumerate(result['subtasks'])
                    ]

                # æ£€ç´¢ç­–ç•¥ä¿¡æ¯
                strategy_info = {
                    "retrieval_results": []
                }

                if 'retrieval_results' in result:
                    strategy_info["retrieval_results"] = [
                        {
                            "query": r.query,
                            "contexts_count": len(r.contexts),
                            "retrieval_time": r.retrieval_time,
                            "retriever_type": r.retriever_type,
                            "metadata": getattr(r, 'metadata', {})
                        }
                        for r in result['retrieval_results']
                    ]

                # è®¡ç®—ç»“æœç»Ÿè®¡
                total_docs = 0
                if 'retrieval_results' in result:
                    total_docs = sum(len(r.contexts) for r in result['retrieval_results'])

                displayed_docs = min(max_results, total_docs)

                return (
                    search_output,
                    gr.update(value=json.dumps(task_info, ensure_ascii=False, indent=2), visible=True),
                    gr.update(value=json.dumps(strategy_info, ensure_ascii=False, indent=2), visible=True),
                    f"{result['processing_time']:.2f} ç§’",
                    f"å…± {total_docs} ä¸ªç»“æœï¼Œæ˜¾ç¤ºå‰ {displayed_docs} ä¸ª"
                )

            except Exception as e:
                import traceback
                error_msg = f"å¤„ç†å‡ºé”™: {str(e)}\n\nè¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}"
                return (
                    error_msg,
                    gr.update(visible=False),
                    gr.update(visible=False),
                    "",
                    ""
                )

        def clear_all():
            """æ¸…ç©ºæ‰€æœ‰å†…å®¹"""
            return (
                "",
                "",
                gr.update(visible=False),
                gr.update(visible=False),
                "",
                ""
            )

        def set_example_query(example_text):
            """è®¾ç½®ç¤ºä¾‹æŸ¥è¯¢"""
            return example_text

        def update_system_status():
            """æ›´æ–°ç³»ç»ŸçŠ¶æ€"""
            try:
                engine.initialize_components()
                corpus_stats = engine.data_manager.get_corpus_stats()

                status_html = "<p><span style='color: green;'>â—</span> ç³»ç»Ÿå·²åˆå§‹åŒ–</p>"
                corpus_html = f"<p><strong>è¯­æ–™åº“:</strong> {corpus_stats['total_documents']} ä¸ªæ–‡æ¡£</p>"

                return status_html, corpus_html
            except Exception as e:
                status_html = f"<p><span style='color: red;'>â—</span> ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}</p>"
                corpus_html = "<p><strong>è¯­æ–™åº“:</strong> åŠ è½½å¤±è´¥</p>"
                return status_html, corpus_html
        
        # ç»‘å®šäº‹ä»¶
        query_components["search_btn"].click(
            fn=process_search,
            inputs=[
                query_components["query_input"],
                query_components["show_details"],
                query_components["max_results"]
            ],
            outputs=[
                query_components["search_results"],
                query_components["task_decomposition"],
                query_components["retrieval_strategy"],
                query_components["processing_time"],
                query_components["total_results"]
            ]
        )

        query_components["clear_btn"].click(
            fn=clear_all,
            outputs=[
                query_components["query_input"],
                query_components["search_results"],
                query_components["task_decomposition"],
                query_components["retrieval_strategy"],
                query_components["processing_time"],
                query_components["total_results"]
            ]
        )

        # é…ç½®æŒ‰é’®äº‹ä»¶ç»‘å®š
        def save_config_handler(*config_values):
            """ä¿å­˜é…ç½®å¤„ç†å™¨"""
            try:
                # è¿™é‡Œå¯ä»¥å®ç°é…ç½®ä¿å­˜é€»è¾‘
                return "âœ… é…ç½®å·²ä¿å­˜"
            except Exception as e:
                return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}"

        def load_config_handler():
            """åŠ è½½é…ç½®å¤„ç†å™¨"""
            try:
                # è¿™é‡Œå¯ä»¥å®ç°é…ç½®åŠ è½½é€»è¾‘
                return "âœ… é…ç½®å·²åŠ è½½"
            except Exception as e:
                return f"âŒ åŠ è½½å¤±è´¥: {str(e)}"

        def reset_config_handler():
            """é‡ç½®é…ç½®å¤„ç†å™¨"""
            try:
                # é‡ç½®ä¸ºé»˜è®¤å€¼
                config = create_flexrag_integrated_config()
                return (
                    "./adaptive_rag/models/e5-base-v2",
                    "./adaptive_rag/models/qwen1.5-1.8b",
                    "./adaptive_rag/models/bge-reranker-base",
                    "./adaptive_rag/data/general_knowledge.jsonl",
                    "./adaptive_rag/data/e5_Flat.index",
                    config.batch_size,
                    "âœ… é…ç½®å·²é‡ç½®ä¸ºé»˜è®¤å€¼"
                )
            except Exception as e:
                return ("", "", "", "", "", 4, f"âŒ é‡ç½®å¤±è´¥: {str(e)}")

        # ç»‘å®šé…ç½®æŒ‰é’®äº‹ä»¶
        basic_components["save_config_btn"].click(
            fn=save_config_handler,
            inputs=[
                basic_components["dense_model_path"],
                basic_components["generator_model_path"],
                basic_components["reranker_model_path"],
                basic_components["corpus_path"],
                basic_components["index_path"],
                basic_components["batch_size"]
            ],
            outputs=[basic_components["config_status"]]
        )

        basic_components["load_config_btn"].click(
            fn=load_config_handler,
            outputs=[basic_components["config_status"]]
        )

        basic_components["reset_config_btn"].click(
            fn=reset_config_handler,
            outputs=[
                basic_components["dense_model_path"],
                basic_components["generator_model_path"],
                basic_components["reranker_model_path"],
                basic_components["corpus_path"],
                basic_components["index_path"],
                basic_components["batch_size"],
                basic_components["config_status"]
            ]
        )

        # é¡µé¢åŠ è½½æ—¶æ›´æ–°ç³»ç»ŸçŠ¶æ€
        demo.load(
            fn=update_system_status,
            outputs=[
                query_components["system_status"],
                query_components["corpus_info"]
            ]
        )
    
    return demo


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="å¯åŠ¨æ™ºèƒ½è‡ªé€‚åº” RAG WebUI")
    parser.add_argument("--port", type=int, default=7860, help="æœåŠ¡ç«¯å£")
    parser.add_argument("--host", type=str, default="0.0.0.0", help="æœåŠ¡ä¸»æœº")
    parser.add_argument("--debug", action="store_true", help="è°ƒè¯•æ¨¡å¼")
    parser.add_argument("--share", action="store_true", help="åˆ›å»ºå…¬å…±é“¾æ¥")
    parser.add_argument("--real-config", action="store_true", help="ä½¿ç”¨çœŸå®é…ç½®")
    parser.add_argument("--config-path", type=str, default="real_config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")

    args = parser.parse_args()

    print(f"ğŸš€ å¯åŠ¨æ™ºèƒ½è‡ªé€‚åº” RAG WebUI")
    print(f"ğŸ“ åœ°å€: http://{args.host}:{args.port}")
    print(f"ğŸ”§ è°ƒè¯•æ¨¡å¼: {args.debug}")
    print(f"âš™ï¸ ä½¿ç”¨çœŸå®é…ç½®: {args.real_config}")

    if args.real_config:
        print(f"ğŸ“ é…ç½®æ–‡ä»¶: {args.config_path}")
        demo = create_ui_with_real_config(args.config_path)
    else:
        demo = create_ui()

    try:
        demo.launch(
            server_name=args.host,
            server_port=args.port,
            share=args.share,
            debug=args.debug,
            show_error=True,
            quiet=False
        )
    except OSError as e:
        if "Cannot find empty port" in str(e):
            print(f"âŒ ç«¯å£ {args.port} è¢«å ç”¨")
            print(f"ğŸ’¡ å°è¯•ä½¿ç”¨å…¶ä»–ç«¯å£:")

            # è‡ªåŠ¨å°è¯•å…¶ä»–ç«¯å£
            for port in range(args.port + 1, args.port + 10):
                try:
                    print(f"ğŸ”„ å°è¯•ç«¯å£ {port}...")
                    demo.launch(
                        server_name=args.host,
                        server_port=port,
                        share=args.share,
                        debug=args.debug,
                        show_error=True,
                        quiet=False
                    )
                    break
                except OSError:
                    continue
            else:
                print(f"âŒ æ— æ³•æ‰¾åˆ°å¯ç”¨ç«¯å£ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®š: python interface.py --port 8080")
        else:
            raise e
