#!/usr/bin/env python3
"""
=== AdaptiveRAG WebUI with Real Config ===

ä½¿ç”¨çœŸå®é…ç½®æ–‡ä»¶è¿è¡Œ AdaptiveRAG WebUIï¼Œå¯è§†åŒ–å±•ç¤ºå„ä¸ªæ¨¡å—
"""

import gradio as gr
import json
import yaml
import time
import logging
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class RealConfigAdaptiveRAG:
    """ä½¿ç”¨çœŸå®é…ç½®çš„ AdaptiveRAG ç³»ç»Ÿ"""
    
    def __init__(self, config_path: str = "real_config.yaml"):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        self.config_path = config_path
        self.config = self.load_config()
        self.last_query_result = None
        
        logger.info("ğŸš€ AdaptiveRAG ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            logger.info(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {self.config_path}")
            return config
        except Exception as e:
            logger.error(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            return self.get_default_config()
    
    def get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "device": "cuda",
            "retriever_configs": {},
            "generator_configs": {},
            "ranker_configs": {}
        }
    
    def get_config_summary(self) -> str:
        """è·å–é…ç½®æ‘˜è¦"""
        summary = []
        summary.append("ğŸ“‹ **å½“å‰é…ç½®æ‘˜è¦**\n")
        
        # åŸºç¡€è®¾ç½®
        summary.append(f"ğŸ–¥ï¸ **è®¾å¤‡**: {self.config.get('device', 'N/A')}")
        summary.append(f"ğŸ”¢ **æ‰¹æ¬¡å¤§å°**: {self.config.get('batch_size', 'N/A')}")
        summary.append(f"ğŸ¯ **æ•°æ®é›†**: {self.config.get('dataset_name', 'N/A')}")
        
        # æ£€ç´¢å™¨é…ç½®
        retrievers = self.config.get('retriever_configs', {})
        summary.append(f"\nğŸ” **æ£€ç´¢å™¨é…ç½®** ({len(retrievers)} ä¸ª):")
        for name, config in retrievers.items():
            retriever_type = config.get('retriever_type', 'unknown')
            status = "âœ… çœŸå®" if retriever_type != "mock" else "ğŸ”„ æ¨¡æ‹Ÿ"
            summary.append(f"   â€¢ {name}: {retriever_type} {status}")
        
        # ç”Ÿæˆå™¨é…ç½®
        generators = self.config.get('generator_configs', {})
        summary.append(f"\nğŸ¤– **ç”Ÿæˆå™¨é…ç½®** ({len(generators)} ä¸ª):")
        for name, config in generators.items():
            generator_type = config.get('generator_type', 'unknown')
            status = "âœ… çœŸå®" if generator_type != "mock" else "ğŸ”„ æ¨¡æ‹Ÿ"
            summary.append(f"   â€¢ {name}: {generator_type} {status}")
        
        # é‡æ’åºå™¨é…ç½®
        rankers = self.config.get('ranker_configs', {})
        summary.append(f"\nğŸ“Š **é‡æ’åºå™¨é…ç½®** ({len(rankers)} ä¸ª):")
        for name, config in rankers.items():
            ranker_type = config.get('ranker_type', 'unknown')
            status = "âœ… çœŸå®" if ranker_type != "mock" else "ğŸ”„ æ¨¡æ‹Ÿ"
            summary.append(f"   â€¢ {name}: {ranker_type} {status}")
        
        return "\n".join(summary)
    
    def process_query(self, query: str) -> Dict[str, Any]:
        """å¤„ç†æŸ¥è¯¢ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼Œå±•ç¤ºæµç¨‹ï¼‰"""
        start_time = time.time()
        
        logger.info(f"ğŸ” å¤„ç†æŸ¥è¯¢: {query}")
        
        # æ¨¡æ‹Ÿå„ä¸ªé˜¶æ®µ
        stages = {
            "query_analysis": self.simulate_query_analysis(query),
            "strategy_planning": self.simulate_strategy_planning(query),
            "retrieval": self.simulate_retrieval(query),
            "reranking": self.simulate_reranking(query),
            "generation": self.simulate_generation(query)
        }
        
        total_time = time.time() - start_time
        
        result = {
            "query": query,
            "stages": stages,
            "total_time": total_time,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        self.last_query_result = result
        return result
    
    def simulate_query_analysis(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹ŸæŸ¥è¯¢åˆ†æé˜¶æ®µ"""
        time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        # ç®€å•çš„æŸ¥è¯¢åˆ†æ
        words = query.lower().split()
        complexity_score = min(len(words) / 10.0, 1.0)
        
        # æ£€æµ‹æŸ¥è¯¢ç±»å‹
        question_words = ['what', 'who', 'where', 'when', 'why', 'how']
        has_question_word = any(word in words for word in question_words)
        
        multi_hop_indicators = ['and', 'also', 'furthermore', 'additionally']
        is_multi_hop = any(indicator in words for indicator in multi_hop_indicators)
        
        return {
            "complexity_score": complexity_score,
            "word_count": len(words),
            "has_question_word": has_question_word,
            "is_multi_hop": is_multi_hop,
            "query_type": "multi_hop" if is_multi_hop else "single_hop",
            "processing_time": 0.1
        }
    
    def simulate_strategy_planning(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿç­–ç•¥è§„åˆ’é˜¶æ®µ"""
        time.sleep(0.1)
        
        # æ ¹æ®æŸ¥è¯¢ç±»å‹é€‰æ‹©ç­–ç•¥
        analysis = self.simulate_query_analysis(query)
        
        if analysis["is_multi_hop"]:
            weights = {"keyword": 0.3, "dense": 0.5, "web": 0.2}
            strategy = "multi_hop_strategy"
        else:
            weights = {"keyword": 0.6, "dense": 0.3, "web": 0.1}
            strategy = "single_hop_strategy"
        
        return {
            "selected_strategy": strategy,
            "retriever_weights": weights,
            "confidence": 0.85,
            "reasoning": f"åŸºäºæŸ¥è¯¢å¤æ‚åº¦ {analysis['complexity_score']:.2f} é€‰æ‹©ç­–ç•¥",
            "processing_time": 0.1
        }
    
    def simulate_retrieval(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæ£€ç´¢é˜¶æ®µ"""
        time.sleep(0.2)
        
        # æ¨¡æ‹Ÿå¤šä¸ªæ£€ç´¢å™¨çš„ç»“æœ
        retrievers = self.config.get('retriever_configs', {})
        results = {}
        
        for retriever_name, config in retrievers.items():
            retriever_type = config.get('retriever_type', 'mock')
            top_k = config.get('top_k', 5)
            
            # æ¨¡æ‹Ÿæ£€ç´¢ç»“æœ
            docs = []
            for i in range(top_k):
                docs.append({
                    "id": f"{retriever_name}_doc_{i}",
                    "title": f"Document {i} from {retriever_name}",
                    "content": f"This is content from {retriever_name} retriever for query: {query[:50]}...",
                    "score": 0.9 - i * 0.1,
                    "source": retriever_name
                })
            
            results[retriever_name] = {
                "type": retriever_type,
                "documents": docs,
                "total_found": top_k,
                "processing_time": 0.05
            }
        
        return {
            "retriever_results": results,
            "total_documents": sum(len(r["documents"]) for r in results.values()),
            "processing_time": 0.2
        }
    
    def simulate_reranking(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿé‡æ’åºé˜¶æ®µ"""
        time.sleep(0.1)
        
        rankers = self.config.get('ranker_configs', {})
        
        # æ¨¡æ‹Ÿé‡æ’åºç»“æœ
        reranked_docs = []
        for i in range(5):
            reranked_docs.append({
                "id": f"reranked_doc_{i}",
                "title": f"Reranked Document {i}",
                "content": f"Reranked content for: {query[:50]}...",
                "original_score": 0.8 - i * 0.1,
                "rerank_score": 0.95 - i * 0.05,
                "rank_change": i % 3 - 1  # -1, 0, 1
            })
        
        return {
            "ranker_used": list(rankers.keys())[0] if rankers else "default",
            "reranked_documents": reranked_docs,
            "score_improvement": 0.15,
            "processing_time": 0.1
        }
    
    def simulate_generation(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿç”Ÿæˆé˜¶æ®µ"""
        time.sleep(0.3)
        
        generators = self.config.get('generator_configs', {})
        main_generator = list(generators.keys())[0] if generators else "default"
        
        # æ¨¡æ‹Ÿç”Ÿæˆçš„ç­”æ¡ˆ
        answer = f"Based on the retrieved information, here's the answer to '{query}': This is a simulated response generated using the {main_generator} generator with real configuration settings."
        
        return {
            "generator_used": main_generator,
            "generated_answer": answer,
            "confidence": 0.88,
            "token_count": len(answer.split()),
            "processing_time": 0.3
        }

def create_webui(config_path: str = "real_config.yaml") -> gr.Blocks:
    """åˆ›å»º WebUI ç•Œé¢"""
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    rag_system = RealConfigAdaptiveRAG(config_path)
    
    # åˆ›å»ºç•Œé¢
    with gr.Blocks(
        title="AdaptiveRAG WebUI",
        theme=gr.themes.Soft(),
        css="""
        .gradio-container {
            max-width: 1200px !important;
            margin: 0 auto !important;
        }
        """
    ) as demo:
        
        gr.HTML("""
        <div style="text-align: center; padding: 20px;">
            <h1>ğŸ§  AdaptiveRAG WebUI</h1>
            <p>æ™ºèƒ½è‡ªé€‚åº”æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿ - ä½¿ç”¨çœŸå®é…ç½®</p>
        </div>
        """)
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        with gr.Tabs():
            # é…ç½®ä¿¡æ¯æ ‡ç­¾é¡µ
            with gr.Tab("âš™ï¸ é…ç½®ä¿¡æ¯"):
                gr.HTML("<h2>ğŸ“‹ ç³»ç»Ÿé…ç½®ä¿¡æ¯</h2>")
                
                config_display = gr.Markdown(
                    value=rag_system.get_config_summary(),
                    label="é…ç½®æ‘˜è¦"
                )
                
                with gr.Row():
                    refresh_config_btn = gr.Button("ğŸ”„ åˆ·æ–°é…ç½®", variant="secondary")
                    reload_config_btn = gr.Button("ğŸ“ é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶", variant="primary")
                
                config_status = gr.Textbox(
                    label="çŠ¶æ€",
                    value="é…ç½®å·²åŠ è½½",
                    interactive=False
                )
                
                def refresh_config():
                    return rag_system.get_config_summary(), "é…ç½®å·²åˆ·æ–°"
                
                def reload_config():
                    rag_system.config = rag_system.load_config()
                    return rag_system.get_config_summary(), "é…ç½®æ–‡ä»¶å·²é‡æ–°åŠ è½½"
                
                refresh_config_btn.click(
                    refresh_config,
                    outputs=[config_display, config_status]
                )
                
                reload_config_btn.click(
                    reload_config,
                    outputs=[config_display, config_status]
                )
            
            # æŸ¥è¯¢æµ‹è¯•æ ‡ç­¾é¡µ
            with gr.Tab("ğŸ” æŸ¥è¯¢æµ‹è¯•"):
                gr.HTML("<h2>ğŸ§  æ™ºèƒ½æŸ¥è¯¢å¤„ç†</h2>")
                
                with gr.Row():
                    with gr.Column(scale=3):
                        query_input = gr.Textbox(
                            label="è¾“å…¥æŸ¥è¯¢",
                            placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
                            lines=3
                        )
                        
                        process_btn = gr.Button("ğŸš€ å¤„ç†æŸ¥è¯¢", variant="primary")
                        
                    with gr.Column(scale=1):
                        gr.HTML("<h4>ğŸ“Š å¿«é€Ÿç»Ÿè®¡</h4>")
                        query_stats = gr.JSON(
                            label="æŸ¥è¯¢ç»Ÿè®¡",
                            value={"æ€»æŸ¥è¯¢æ•°": 0, "å¹³å‡å¤„ç†æ—¶é—´": "0.0s"}
                        )
                
                # ç»“æœå±•ç¤ºåŒºåŸŸ
                with gr.Row():
                    with gr.Column():
                        gr.HTML("<h3>ğŸ“ˆ å¤„ç†æµç¨‹</h3>")
                        process_flow = gr.JSON(label="å¤„ç†é˜¶æ®µ")
                        
                    with gr.Column():
                        gr.HTML("<h3>ğŸ’¬ ç”Ÿæˆç»“æœ</h3>")
                        generated_answer = gr.Textbox(
                            label="ç”Ÿæˆçš„ç­”æ¡ˆ",
                            lines=5,
                            interactive=False
                        )
                
                def process_query(query):
                    if not query.strip():
                        return {}, "è¯·è¾“å…¥æœ‰æ•ˆçš„æŸ¥è¯¢"
                    
                    result = rag_system.process_query(query)
                    
                    # æå–å¤„ç†æµç¨‹ä¿¡æ¯
                    flow_info = {}
                    for stage_name, stage_data in result["stages"].items():
                        flow_info[stage_name] = {
                            "å¤„ç†æ—¶é—´": f"{stage_data.get('processing_time', 0):.3f}s",
                            "çŠ¶æ€": "âœ… å®Œæˆ"
                        }
                    
                    flow_info["æ€»å¤„ç†æ—¶é—´"] = f"{result['total_time']:.3f}s"
                    
                    # æå–ç”Ÿæˆçš„ç­”æ¡ˆ
                    answer = result["stages"]["generation"]["generated_answer"]
                    
                    return flow_info, answer
                
                process_btn.click(
                    process_query,
                    inputs=[query_input],
                    outputs=[process_flow, generated_answer]
                )
    
    return demo

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨ AdaptiveRAG WebUI")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_path = "real_config.yaml"
    if not Path(config_path).exists():
        logger.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return
    
    # åˆ›å»ºå¹¶å¯åŠ¨ WebUI
    demo = create_webui(config_path)
    
    logger.info("ğŸŒ å¯åŠ¨ WebUI æœåŠ¡å™¨...")
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        debug=True
    )

if __name__ == "__main__":
    main()
